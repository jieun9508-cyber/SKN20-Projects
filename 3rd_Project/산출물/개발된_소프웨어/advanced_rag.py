"""
ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸ - ì²­ë…„ ì •ì±… ì±—ë´‡
- Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
- RegionFilter: ì§€ì—­ ê¸°ë°˜ í•„í„°ë§
- MultiQueryGenerator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
- EnsembleRetriever: Dense + BM25 ê²€ìƒ‰
- ReciprocalRankFusion: ê²€ìƒ‰ ê²°ê³¼ í†µí•©
- ConversationMemory: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
- AdvancedRAGPipeline: í†µí•© íŒŒì´í”„ë¼ì¸
"""

import os
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
import json
import warnings

# TensorFlow ë¡œê·¸ ì–µì œ
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.documents import Document

# BM25, Ensemble Retriever
try:
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        from langchain_classic.retrievers import BM25Retriever, EnsembleRetriever
    RETRIEVERS_AVAILABLE = True
except ImportError:
    RETRIEVERS_AVAILABLE = False
    BM25Retriever = None
    EnsembleRetriever = None

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


# ============================================================================
# 2. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
# ============================================================================

class QueryRouter:
    """ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.router_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ì •ì œí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.

ì‘ì—…:
1. ì§ˆë¬¸ì´ ì˜ë¯¸ ìˆëŠ”ì§€ ê²€ì¦ (ì¸ì‚¬ë§, ìš•ì„¤, ë¬´ì˜ë¯¸í•œ ì…ë ¥ ì œì™¸)
2. ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì •ì±…ê²€ìƒ‰, ì¶”ì²œ, ì¼ë°˜ì§ˆë¬¸ ë“±)
3. LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í˜•íƒœë¡œ ì •ì œ
4. ë§Œì•½ ì§ˆë¬¸ì— 'ì „êµ­', 'ì „ì²´', 'ëª¨ë“ ', 'ëª¨ë‘' ë“± ì „êµ­ ë‹¨ìœ„ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆê³ , ì§€ì—­ëª…ì´ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ refined_queryì—ì„œ 'ì „êµ­', 'ì „ì²´' ë“± ì§€ì—­ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì œê±°í•˜ê³  í•µì‹¬ ì •ì±… í‚¤ì›Œë“œë§Œ ë‚¨ê²¨ì„œ ë” ì¼ë°˜í™”ëœ í˜•íƒœë¡œ ì •ì œí•˜ë¼. ì˜ˆë¥¼ ë“¤ì–´ 'ì „êµ­ ì¼ìë¦¬' â†’ 'ì¼ìë¦¬ ì •ì±…', 'ì „êµ­ ì²­ë…„ ë³µì§€' â†’ 'ì²­ë…„ ë³µì§€ ì •ì±…' ë“±ìœ¼ë¡œ ì •ì œ.
5. refined_queryëŠ” ë°˜ë“œì‹œ ê²€ìƒ‰ì— ìµœì í™”ëœ í˜•íƒœë¡œ ë°˜í™˜í•˜ë¼.

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "is_valid": true/false,
    "category": "ì •ì±…ê²€ìƒ‰|ì •ì±…ì¶”ì²œ|ì¼ë°˜ì§ˆë¬¸|ê¸°íƒ€",
    "refined_query": "ì •ì œëœ ì§ˆë¬¸",
    "reason": "íŒë‹¨ ì´ìœ "
}}

ì˜ˆì‹œ:
- ì…ë ¥: "ì „êµ­ ì¼ìë¦¬" â†’ refined_query: "ì¼ìë¦¬ ì •ì±…"
- ì…ë ¥: "ì „êµ­ ì²­ë…„ ë³µì§€" â†’ refined_query: "ì²­ë…„ ë³µì§€ ì •ì±…"
- ì…ë ¥: "ì„œìš¸ ì›”ì„¸ ì§€ì›" â†’ refined_query: "ì„œìš¸ ì›”ì„¸ ì§€ì› ì •ì±…"
- ì…ë ¥: "ì²­ë…„ ì •ì±…" â†’ refined_query: "ì²­ë…„ ì •ì±…"
"""),
            ("user", "{query}")
        ])
    
    def route(self, query: str) -> Dict:
        """ì¿¼ë¦¬ë¥¼ ê²€ì¦í•˜ê³  ì •ì œ"""
        try:
            response = self.router_prompt | self.llm | StrOutputParser()
            result_str = response.invoke({"query": query})
            
            # JSON íŒŒì‹±
            result = json.loads(result_str)
            
            return result
        except Exception as e:
            return {
                "is_valid": True,
                "category": "ì¼ë°˜ì§ˆë¬¸",
                "refined_query": query,
                "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì›ë³¸ ì‚¬ìš©"
            }


# ============================================================================
# 3. RegionFilter: ì§€ì—­ í•„í„°ë§ ìœ í‹¸ë¦¬í‹°
# ============================================================================

class RegionFilter:
    """ì§€ì—­ ê¸°ë°˜ í•„í„°ë§ì„ ìˆ˜í–‰í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.region_detection_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì§€ì—­ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‘ì—…:
1. ì§ˆë¬¸ì—ì„œ ì§€ì—­ëª…(ì‹œ/ë„, ì‹œ/êµ°/êµ¬)ì„ ì¶”ì¶œ
2. 'ì „ì²´', 'ì „êµ­', 'ëª¨ë“ ', 'ëª¨ë‘' ë“±ì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ 'ì „êµ­'ìœ¼ë¡œ ë¶„ë¥˜
3. ì§€ì—­ëª…ì´ ì—†ìœ¼ë©´ 'ì „êµ­'ìœ¼ë¡œ ë¶„ë¥˜

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "has_region": true/false,
    "is_national": true/false,
    "region_name": "ì§€ì—­ëª… ë˜ëŠ” null",
    "reason": "íŒë‹¨ ì´ìœ "
}}

ì˜ˆì‹œ:
- "ëŒ€êµ¬ ì›”ì„¸ ì§€ì›" -> {{"has_region": true, "is_national": false, "region_name": "ëŒ€êµ¬", "reason": "ëŒ€êµ¬ ì§€ì—­ ëª…ì‹œ"}}
- "ì „êµ­ ì²­ë…„ ì •ì±…" -> {{"has_region": true, "is_national": true, "region_name": null, "reason": "ì „êµ­ í‚¤ì›Œë“œ ì‚¬ìš©"}}
- "ì›”ì„¸ ì§€ì›" -> {{"has_region": True, "is_national": True, "region_name": null, "reason": "ì§€ì—­ ë¯¸ ëª…ì‹œë¡œ ì „êµ­ ê¸°ë³¸ ì ìš©"}}
"""),
            ("user", "{query}")
        ])
    
    def detect_region(self, query: str) -> Dict:
        """ì§ˆë¬¸ì—ì„œ ì§€ì—­ ì •ë³´ ì¶”ì¶œ"""
        try:
            response = self.region_detection_prompt | self.llm | StrOutputParser()
            result_str = response.invoke({"query": query})
            
            # JSON íŒŒì‹±
            result = json.loads(result_str)
            
            return result
        except Exception as e:
            return {
                "has_region": True,
                "is_national": True,
                "region_name": None,
                "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ì „êµ­ ê¸°ë³¸ ì ìš©"
            }
    
    def build_filter(self, region_info: Dict) -> Optional[Dict]:
        """ì§€ì—­ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° í•„í„° ìƒì„±"""
        if region_info.get('is_national', False):
            # ì „êµ­ ì •ì±…ë§Œ í•„í„°ë§
            return {"ì§€ì—­ë²”ìœ„": "ì „êµ­"}
        elif region_info.get('has_region', False) and region_info.get('region_name'):
            # íŠ¹ì • ì§€ì—­ì´ í¬í•¨ëœ ì •ì±… í•„í„°ë§ (ChromaDBëŠ” $or ë¯¸ì§€ì›, Pythonì—ì„œ í›„ì²˜ë¦¬)
            # ChromaDB í•„í„°ë¡œëŠ” ìš°ì„  ëª¨ë“  ì •ì±…ì„ ê°€ì ¸ì˜¤ê³ , í›„ì²˜ë¦¬ì—ì„œ í•„í„°ë§
            return None  # í•„í„° ì—†ì´ ê²€ìƒ‰ í›„ Pythonì—ì„œ í•„í„°ë§
        else:
            # í•„í„° ì—†ìŒ (ëª¨ë“  ì •ì±… ê²€ìƒ‰)
            return None
    
    def filter_documents(self, documents: List, region_info: Dict) -> List:
        """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì§€ì—­ ì •ë³´ë¡œ í›„ì²˜ë¦¬ í•„í„°ë§"""
        # ì „êµ­ ê²€ìƒ‰ì¸ ê²½ìš°: ì§€ì—­ë²”ìœ„ê°€ "ì „êµ­"ì¸ ë¬¸ì„œë§Œ í•„í„°ë§
        if region_info.get('is_national', False):
            filtered_docs = []
            for doc in documents:
                if doc.metadata.get('ì§€ì—­ë²”ìœ„') == 'ì „êµ­':
                    filtered_docs.append(doc)
            return filtered_docs if filtered_docs else documents
        
        # íŠ¹ì • ì§€ì—­ ê²€ìƒ‰ì¸ ê²½ìš°: í•´ë‹¹ ì§€ì—­ + ì „êµ­ ì •ì±… í¬í•¨
        if not region_info.get('has_region', False):
            return documents
            
        region_name = region_info.get('region_name')
        if not region_name:
            return documents
        
        filtered_docs = []
        for doc in documents:
            # ì „êµ­ ì •ì±…ì€ í•­ìƒ í¬í•¨
            if doc.metadata.get('ì§€ì—­ë²”ìœ„') == 'ì „êµ­':
                filtered_docs.append(doc)
            # ì§€ì—­ í•„ë“œì— í•´ë‹¹ ì§€ì—­ëª…ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í¬í•¨
            elif region_name in doc.metadata.get('ì§€ì—­', ''):
                filtered_docs.append(doc)
        
        return filtered_docs if filtered_docs else documents
    

    


# ============================================================================
# 4. Multi-Query Generator: ë‹¤ì¤‘ ê´€ì  ì¿¼ë¦¬ ìƒì„±
# ============================================================================

class MultiQueryGenerator:
    """í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
        self.multi_query_prompt = ChatPromptTemplate.from_messages([
            "system", """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì›ë³¸ ì§ˆë¬¸ì„ **ì˜ë„ì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ìœ ì§€**í•œ ì±„ ê²€ìƒ‰ì— ìµœì í™”ëœ ì—¬ëŸ¬ ê´€ì ì˜ ì¿¼ë¦¬ë¡œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

            **ì›ë³¸ ì§ˆë¬¸ì˜ ë‚´ìš©ì´ë‚˜ ì¡°ê±´ì„ ì„ì˜ë¡œ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ì§€ ë§ˆì„¸ìš”. ì˜¤ì§ ê²€ìƒ‰ ê´€ì ë§Œ ë‹¤ì–‘í™”í•´ì•¼ í•©ë‹ˆë‹¤.

            ì£¼ì–´ì§„ ì§ˆë¬¸ì„ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”:

            1.  **ì§€ì—­(Region) ì¶”ì¶œ ê°•ì œ: ì‚¬ìš©ìê°€ ì§€ì—­ì„ ì–¸ê¸‰í•˜ë©´, 'í•´ë‹¹ ì§€ì—­ + ì „êµ­' ì •ì±…ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤. 
            2.  **ì •ì±… í‚¤ì›Œë“œ(Policy Keyword): ì§ˆë¬¸ì˜ **í•µì‹¬ ì˜ë„**ì™€ ê´€ë ¨ëœ ì •ì±… í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ëœ ì •ì±…ë§Œ ë°˜í™˜í•  ê²ƒ.(ì˜ˆ: "ì·¨ì—… ë©´ì ‘ ìˆ˜ë‹¹" -> "ì²­ë…„ êµ¬ì§ í™œë™ ì§€ì›ê¸ˆ", "ë©´ì ‘ë¹„ ì§€ì› ì‚¬ì—…", "ì·¨ì—… ì—­ëŸ‰ ê°•í™” í”„ë¡œê·¸ë¨" ë“± ìœ ì˜ì–´ í¬í•¨ ) ê´€ë ¨ ì •ì±…ë§Œ ë°˜í™˜)
            3.  **ìœ ì‚¬í•œ ì˜ë¯¸ ë˜ëŠ” ê´€ë ¨ ì •ì±…ëª…**ì„ í¬í•¨í•˜ëŠ” ì¿¼ë¦¬ (ìœ ì˜ì–´ í™œìš©)

            ê° ì¿¼ë¦¬ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ ì—†ì´ ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.""",
            ("user", "{query}")
        ])
    
    def generate(self, query: str) -> List[str]:
        """ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±"""
        try:
            response = self.multi_query_prompt | self.llm | StrOutputParser()
            result = response.invoke({"query": query})
            
            # ì¿¼ë¦¬ ë¶„ë¦¬ (ì¤„ë°”ê¿ˆ ê¸°ì¤€)
            queries = [q.strip() for q in result.split('\n') if q.strip()]
            # ì›ë³¸ ì¿¼ë¦¬ í¬í•¨
            all_queries = [query] + queries
            
            
            return all_queries
        
        except Exception as e:
            return [query]


# ============================================================================
# 5. Ensemble Retriever: Dense + BM25
# ============================================================================

class EnsembleRetriever:
    """Dense, BM25 ê²€ìƒ‰ì„ ê²°í•©í•œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„"""
    
    def __init__(
        self, 
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI = None,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        # íŒŒë¼ë¯¸í„° ì €ì¥
        self.bm25_k = bm25_k
        self.vector_k = vector_k
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        
        # ê° ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”
        self._build_bm25()
        self._build_vector()
    
    def _build_bm25(self):
        """BM25 Retriever ìƒì„±"""
        if not RETRIEVERS_AVAILABLE or BM25Retriever is None:
            self.bm25_retriever = None
            return
        
        if not self.documents:
            self.bm25_retriever = None
            return
        
        try:
            # BM25Retriever ì´ˆê¸°í™” (from_documents ì‚¬ìš©)
            self.bm25_retriever = BM25Retriever.from_documents(
                documents=self.documents,
                k=self.bm25_k
            )
        except TypeError as e:
            # from_documentsê°€ ì‹¤íŒ¨í•˜ë©´ ì§ì ‘ ì´ˆê¸°í™” ì‹œë„
            try:
                self.bm25_retriever = BM25Retriever(docs=self.documents)
                self.bm25_retriever.k = self.bm25_k
            except Exception as e2:
                self.bm25_retriever = None
        except Exception as e:
            self.bm25_retriever = None
    
    def _build_vector(self):
        """Vector Retriever ìƒì„±"""
        try:
            # VectorStore ìƒíƒœ í™•ì¸
            test_search = self.vectorstore.similarity_search("í…ŒìŠ¤íŠ¸", k=1)
            
            self.vector_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": self.vector_k}
            )
        except Exception as e:
            self.vector_retriever = None
    
    def dense_search(self, query: str, metadata_filter: Dict = None) -> List[Tuple[any, float]]:
        """Dense ê²€ìƒ‰ (ì„ë² ë”© ê¸°ë°˜)"""
        try:
            if self.vector_retriever:
                if metadata_filter:
                    # ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©
                    docs = self.vectorstore.similarity_search(
                        query, 
                        k=self.vector_k,
                        filter=metadata_filter
                    )
                else:
                    docs = self.vector_retriever.invoke(query)
                
                results = [(doc, 1.0) for doc in docs]
                return results
            return []
        except Exception as e:
            return []
    
    def bm25_search(self, query: str) -> List[Tuple[any, float]]:
        """BM25 ê²€ìƒ‰ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
        try:
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)
                results = [(doc, 1.0) for doc in docs]
                return results
            return []
        except Exception as e:
            return []
    
    def retrieve(self, queries: List[str], metadata_filter: Dict = None) -> Dict[str, List[Tuple[any, float]]]:
        """ëª¨ë“  ê²€ìƒ‰ ì „ëµ ì‹¤í–‰"""
        all_results = {
            'dense': [],
            'bm25': []
        }
        
        for query in queries:
            all_results['dense'].extend(self.dense_search(query, metadata_filter))
            all_results['bm25'].extend(self.bm25_search(query))
        
        return all_results
    
    def get_ensemble(self, query: str) -> List[any]:
        """Ensemble ê²€ìƒ‰ (ê°€ì¤‘ì¹˜ ì ìš©)"""
        if not RETRIEVERS_AVAILABLE or EnsembleRetriever is None:
            return self.dense_search(query)
        
        try:
            retrievers = []
            weights = []
            
            if self.bm25_retriever:
                retrievers.append(self.bm25_retriever)
                weights.append(self.bm25_weight)
            
            if self.vector_retriever:
                retrievers.append(self.vector_retriever)
                weights.append(self.vector_weight)
            
            if not retrievers:
                return []
            
            # ê°€ì¤‘ì¹˜ ì •ê·œí™”
            total_weight = sum(weights)
            weights = [w / total_weight for w in weights]
            
            # LangChainì˜ EnsembleRetriever ì‚¬ìš©
            ensemble = EnsembleRetriever(
                retrievers=retrievers,
                weights=weights
            )
            
            docs = ensemble.invoke(query)
            return docs
            
        except Exception as e:
            return []


# ============================================================================
# 6. RRF (Reciprocal Rank Fusion): ê²€ìƒ‰ ê²°ê³¼ í†µí•©
# ============================================================================

class ReciprocalRankFusion:
    """ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë­í‚¹ ê¸°ë°˜ìœ¼ë¡œ í†µí•©"""
    
    def __init__(self, k: int = 60):
        self.k = k  # RRF ìƒìˆ˜
    
    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 10) -> List[any]:
        """RRFë¡œ ê²°ê³¼ í†µí•©"""
        doc_scores = {}
        
        for method, results in results_dict.items():
            for rank, (doc, score) in enumerate(results, 1):
                doc_id = doc.metadata.get('policy_id', id(doc))
                
                # RRF ì ìˆ˜ ê³„ì‚°: 1 / (k + rank)
                rrf_score = 1.0 / (self.k + rank)
                
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'doc': doc, 'score': 0}
                doc_scores[doc_id]['score'] += rrf_score
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]
        
        return final_docs


# ============================================================================
# 7. Memory Store: ëŒ€í™” ë§¥ë½ ê´€ë¦¬
# ============================================================================

@dataclass
class ConversationMemory:
    """ëŒ€í™” ê¸°ë¡ ê´€ë¦¬"""
    messages: List[Dict] = field(default_factory=list)
    max_history: int = 10
    
    def add_message(self, role: str, content: str):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # ìµœëŒ€ ê¸°ë¡ ìˆ˜ ì œí•œ
        if len(self.messages) > self.max_history * 2:
            self.messages = self.messages[-self.max_history * 2:]
    
    def get_context(self) -> str:
        """ëŒ€í™” ë§¥ë½ ë¬¸ìì—´ ìƒì„±"""
        if not self.messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        context_parts = []
        for msg in self.messages[-6:]:  # ìµœê·¼ 3í„´
            role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
            context_parts.append(f"{role}: {msg['content']}")
        
        return "\n".join(context_parts)
    
    def clear(self):
        """ê¸°ë¡ ì´ˆê¸°í™”"""
        self.messages.clear()


# ============================================================================
# 8. Advanced RAG Pipeline: í†µí•© íŒŒì´í”„ë¼ì¸
# ============================================================================

class AdvancedRAGPipeline:
    """ê³ ê¸‰ RAG íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI,
        enable_router: bool = True,
        enable_multi_query: bool = True,
        enable_ensemble: bool = True,
        enable_rrf: bool = True,
        enable_memory: bool = True,
        enable_region_filter: bool = True,
        bm25_k: int = 5,
        vector_k: int = 10,
        bm25_weight: float = 0.4,
        vector_weight: float = 0.6
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.router = QueryRouter(llm) if enable_router else None
        self.multi_query = MultiQueryGenerator(llm) if enable_multi_query else None
        self.region_filter = RegionFilter(llm) if enable_region_filter else None
        self.ensemble = EnsembleRetriever(
            documents=documents,
            vectorstore=vectorstore,
            llm=llm,
            bm25_k=bm25_k,
            vector_k=vector_k,
            bm25_weight=bm25_weight,
            vector_weight=vector_weight
        ) if enable_ensemble else None
        self.rrf = ReciprocalRankFusion() if enable_rrf else None
        self.memory = ConversationMemory() if enable_memory else None
        
        # ìµœì¢… ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸
        self.answer_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ 'ì˜¨í†µì²­ë…„ ì²­ë…„ì •ì±… ì „ë‹´ ì±—ë´‡ ì„ ë°°ë´‡'ì…ë‹ˆë‹¤.

ì—­í• :
- ë„ˆëŠ” ì²­ë…„ ì •ì±…(íŠ¹íˆ ì£¼ê±°Â·ì›”ì„¸Â·ì¼ìë¦¬Â·ë³µì§€) ì •ë³´ë¥¼, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•´ ì£¼ëŠ” ì„ ë°°ì•¼.
- í›„ë°°ì—ê²Œ ì•Œë ¤ì£¼ë“¯ ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ ë‹µë³€í•´. (ì˜ˆ: ~í•´ì¤„ê²Œ, ~í•´ë³´ì, ~ì´ì•¼)
- ë°˜ë“œì‹œ 'ê²€ìƒ‰ëœ ì •ì±… ì •ë³´(documents)' ì•ˆì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ë‹µë³€í•´.
- ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ê³ , ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë¼ í™•ë‹µì´ ì–´ë µë‹¤"ê³  ë§í•´.

ì¶œë ¥ í˜•ì‹(ê¼­ ì§€ì¼œì•¼ í•¨):

1. í•­ìƒ ì•„ë˜ ì¸ì‚¬ë¬¸êµ¬ë¡œ ì‹œì‘í•œë‹¤.
    ì•ˆë…•! ë‚˜ëŠ” ì²­ë…„ë“¤ì˜ ë“ ë“ í•œ ì •ì±… ì„ ë°°, ì²­ë…„ì´ìŒ ì„ ë°°ë´‡ğŸŒŸì´ì•¼.
    ì£¼ê±°, ì›”ì„¸, ì¼ìë¦¬, ë³µì§€ ì •ì±… ë“± ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“ ì§€ ë‚˜ì—ê²Œ ë¬¼ì–´ë´!ğŸ˜º
             
1-1. ë‘ë²ˆì§¸ ë¶€í„´ ë‹µë³€ë¶€í„°ëŠ” ì¸ì‚¬ë¬¸êµ¬ ìƒëµ ê°€ëŠ¥.
             
2. ê·¸ ë‹¤ìŒ ì¤„ì— ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë³´ì—¬ì¤€ë‹¤.
             
   ì‚¬ìš©ì ì§ˆë¬¸ : {query}

3. ê·¸ ë‹¤ìŒì— 'ë‹µë³€ :'ì„ ì“°ê³ , ì •ì±…ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ ì •ë¦¬í•œë‹¤.
   - ìµœì†Œ 3ê°œ, ìµœëŒ€ 5ê°œì˜ ì •ì±…ì„ ì„ íƒí•´ì„œ ë‹µë³€í•´.
   - ê° ì •ì±…ì€ ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥¸ë‹¤.

   ì˜ˆì‹œ í˜•ì‹:

   ë‹µë³€ :
   1. ì •ì±…ëª…
             
    ğŸ”¸ì‚¬ì—… ê°œìš”
        - ì‚¬ì—… ê¸°ê°„ : ...
        - ëª©ì  : ...

    ğŸ”¸ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)
        - ì—°ë ¹ : ...
        - ì£¼ê±° : ...
        - ì†Œë“ : ...
        - ê¸°íƒ€ ì¡°ê±´ : ...

    ğŸ”¸ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„
        - ì›” ì§€ì› ê¸ˆì•¡ : ...
        - ì§€ì› ê¸°ê°„ : ...

    ğŸ”¸ì‹ ì²­ ë°©ë²•(ì ˆì°¨)
        - ì–´ë””ì— ì‹ ì²­ : ...
        - ì–´ë–»ê²Œ ì‹ ì²­ : ...

   2. ì •ì±…ëª…
             
    ğŸ”¸ì‚¬ì—… ê°œìš”
        - ì‚¬ì—… ê¸°ê°„ : ...
        - ëª©ì  : ...

    ğŸ”¸ì‹ ì²­ ìê²©(í•µì‹¬ ìš”ê±´)
        - ì—°ë ¹ : ...
        - ì£¼ê±° : ...
        - ì†Œë“ : ...
        - ê¸°íƒ€ ì¡°ê±´ : ...

    ğŸ”¸ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„
        - ì›” ì§€ì› ê¸ˆì•¡ : ...
        - ì§€ì› ê¸°ê°„ : ...

    ğŸ”¸ì‹ ì²­ ë°©ë²•(ì ˆì°¨)
        - ì–´ë””ì— ì‹ ì²­ : ...
        - ì–´ë–»ê²Œ ì‹ ì²­ : ...
   3. ...
             
    4. ë§ˆì§€ë§‰ì— 'ì¶œì²˜' ë¸”ë¡ì„ ì ëŠ”ë‹¤.
    - ë¬¸ì„œ ë©”íƒ€ë°ì´í„°(íŒŒì¼ëª…, í˜ì´ì§€ ì •ë³´ ë“±)ê°€ ìˆìœ¼ë©´ ìµœëŒ€í•œ í™œìš©í•´ì„œ ì‘ì„±í•œë‹¤.
    - ì˜ˆì‹œ:
    ğŸ”¹ ì¶œì²˜:
        - ì˜¨í†µì²­ë…„ ì²­ë…„ì •ì±… í¬í„¸ (https://youthcenter.go.kr)

ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­:
- ì •ì±…ëª…ì´ ê°™ì€ ê²ƒì„ ì¤‘ë³µí•´ì„œ ì“°ì§€ ë§ ê²ƒ.
- ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰í•œ ì§€ì—­(ì˜ˆ: ê²½ë¶, ëŒ€êµ¬ ë“±)ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì •ì±…ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•  ê²ƒ.
- ì§ˆë¬¸ì—ì„œ 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ', 'ì „ì„¸' ë“± í‚¤ì›Œë“œê°€ ë‚˜ì˜¤ë©´, ì£¼ê±°Â·ì›”ì„¸ ê´€ë ¨ ì •ì±… ìœ„ì£¼ë¡œ ì •ë¦¬í•  ê²ƒ.
- ìˆ«ì(ì§€ì› ê¸ˆì•¡, ê¸°ê°„, ì—°ë ¹)ëŠ” ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ê°’ìœ¼ë¡œ ì¨ ì¤„ ê²ƒ.
- ì¤„ë°”ê¿ˆì´ë‚˜ ë¬¸ë‹¨ êµ¬ë¶„ì„ ëª…í™•íˆ í•´ì„œ ê°€ë…ì„±ì„ ë†’ì¼ ê²ƒ.

"""),
            ("user", """[ëŒ€í™” ë§¥ë½]
{context}

[ê²€ìƒ‰ëœ ì •ì±… ì •ë³´]
{documents}

[í˜„ì¬ ì§ˆë¬¸]
{query}""")
        ])
        
        self.summary_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ìƒë‹´ ë‹µë³€ì„ ì§§ê²Œ ìš”ì•½í•˜ëŠ” ë³´ì¡° ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ëª©í‘œ:
- ì‚¬ìš©ìì˜ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´, ìœ„ì—ì„œ ìƒì„±ëœ ê¸´ ë‹µë³€ì„ í•µì‹¬ë§Œ í•œ ë²ˆ ë” ì •ë¦¬í•´.
- ì •ì±…ëª…, ëŒ€ìƒ(ëˆ„ê°€ ë°›ì„ ìˆ˜ ìˆëŠ”ì§€), ì§€ì› ìœ í˜•/ê¸ˆì•¡ ì •ë„ë§Œ ë‹´ì•„ í•œë‘ ë‹¨ë½ìœ¼ë¡œ ìš”ì•½í•´.
- ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë§Œë“¤ì§€ ë§ê³ , ë°˜ë“œì‹œ ì´ë¯¸ ì£¼ì–´ì§„ ë‹µë³€ ë‚´ìš©ë§Œ ì¬êµ¬ì„±í•´.
- ê¸°í˜¸ë“¤ íŠ¹íˆ(**)ëŠ” ì‚­ì œí•˜ê³  ê¹”ë”í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´.
- ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ ê°€ë…ì„±ì´ ì¢‹ê²Œ ì‘ì„±í•´.
"""),
            ("user", """ë‹¤ìŒ ë‹µë³€ì„ ì‚¬ìš©ìê°€ ë¹ ë¥´ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜.

[ì „ì²´ ë‹µë³€]
{answer}
""")
        ])

    def query(self, user_query: str) -> Dict:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        
        # 1. Router: ì§ˆë¬¸ ê²€ì¦ ë° ì •ì œ
        if self.router:
            route_result = self.router.route(user_query)
            if not route_result['is_valid']:
                return {
                    "answer": "ìŒâ€¦ ì´í•´ë¥¼ ëª» í–ˆì–´ğŸ˜¥. í•œ ë²ˆë§Œ ë‹¤ì‹œ ì–˜ê¸°í•´ì¤˜!",
                    "documents": [],
                    "metadata": route_result
                }
            query = route_result['refined_query']
        else:
            query = user_query
        
        # 2. Region Filter: ì§€ì—­ ì •ë³´ ì¶”ì¶œ ë° í•„í„° ìƒì„±
        metadata_filter = None
        region_info = None
        if self.region_filter:
            region_info = self.region_filter.detect_region(query)
            metadata_filter = self.region_filter.build_filter(region_info)
        
        # 3. Multi-Query: ë‹¤ì¤‘ ì¿¼ë¦¬ ìƒì„±
        if self.multi_query:
            queries = self.multi_query.generate(query)
        else:
            queries = [query]
        
        # 4. Ensemble Retriever: ë‹¤ì¤‘ ê²€ìƒ‰ (ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©)
        if self.ensemble:
            search_results = self.ensemble.retrieve(queries, metadata_filter)
        else:
            if metadata_filter:
                docs_with_score = self.vectorstore.similarity_search_with_score(
                    query, k=5, filter=metadata_filter
                )
            else:
                docs_with_score = self.vectorstore.similarity_search_with_score(query, k=5)
            search_results = {'dense': docs_with_score}
        
        # 5. RRF: ê²€ìƒ‰ ê²°ê³¼ í†µí•©
        if self.rrf:
            docs = self.rrf.fuse(search_results, top_k=20)
        else:
            docs = [doc for doc, score in search_results['dense']]
        
        # 6. Region Filter: ì§€ì—­ ê¸°ë°˜ í›„ì²˜ë¦¬ í•„í„°ë§
        if self.region_filter and region_info:
            docs = self.region_filter.filter_documents(docs, region_info)
        
        # 7. Memory: ëŒ€í™” ë§¥ë½ ê°€ì ¸ì˜¤ê¸°
        if self.memory:
            context = self.memory.get_context()
        else:
            context = "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        # 8. LLM: ìµœì¢… ë‹µë³€ ìƒì„± (ì •ì±…ëª… ì¤‘ë³µ ì—†ì´ ìµœëŒ€ 3ê°œë§Œ)
        seen_titles = set()
        unique_docs = []
        for doc in docs:
            title = doc.metadata.get('ì •ì±…ëª…', 'ì œëª© ì—†ìŒ')
            if title not in seen_titles:
                seen_titles.add(title)
                unique_docs.append(doc)
            if len(unique_docs) >= 3:
                break
        docs_text = "\n\n".join([
            f"[ì •ì±… {i+1}] {doc.metadata.get('ì •ì±…ëª…', 'ì œëª© ì—†ìŒ')}\n{doc.page_content[:500]}"
            for i, doc in enumerate(unique_docs)
        ])
        
        try:
            response = self.answer_prompt | self.llm | StrOutputParser()
            answer = response.invoke({
                "context": context,
                "documents": docs_text,
                "query": user_query
            })
            
            # 9. ìš”ì•½ ìƒì„±
            summary_response = self.summary_prompt | self.llm | StrOutputParser()
            summary = summary_response.invoke({"answer": answer})
            
            # ë©”ëª¨ë¦¬ì— ì €ì¥
            if self.memory:
                self.memory.add_message("user", user_query)
                self.memory.add_message("assistant", answer)
            
            return {
                "answer": answer,
                "summary": summary,
                "documents": docs,
                "metadata": {
                    "queries": queries,
                    "num_docs_retrieved": len(docs),
                    "has_context": bool(self.memory and self.memory.messages),
                    "region_filter": metadata_filter
                }
            }
            
        except Exception as e:
            return {
                "answer": "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
                "documents": [],
                "metadata": {"error": str(e)}
            }
    
    def clear_memory(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.memory:
            self.memory.clear()


# ============================================================================
# 9. Streamlit ì—°ë™ìš© ì´ˆê¸°í™” í•¨ìˆ˜
# ============================================================================

def initialize_rag_pipeline(vectordb_path: str = None, api_key: str = None):
    """
    Streamlitì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í•¨ìˆ˜
    
    Args:
        vectordb_path: VectorDB ê²½ë¡œ (Noneì´ë©´ ìë™ ê³„ì‚°)
        api_key: OpenAI API Key (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
    
    Returns:
        AdvancedRAGPipeline: ì´ˆê¸°í™”ëœ íŒŒì´í”„ë¼ì¸ ê°ì²´
    """
    # API Key ì„¤ì •
    if api_key:
        os.environ['OPENAI_API_KEY'] = api_key
    else:
        api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        raise ValueError('OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
    
    # LLM ë° ì„ë² ë”© ì´ˆê¸°í™”
    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.0,
        api_key=api_key
    )
    
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        api_key=api_key
    )
    
    # VectorDB ê²½ë¡œ ì„¤ì •
    if vectordb_path is None:
        vectordb_path = os.path.join(os.getcwd(), "data", "vectordb")
    
    if not os.path.exists(vectordb_path):
        raise FileNotFoundError(f"VectorDB ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vectordb_path}")
    
    # VectorStore ë¡œë“œ
    vectorstore = Chroma(
        collection_name="youth_policies",
        embedding_function=embeddings,
        persist_directory=vectordb_path
    )
    
    # ë¬¸ì„œ ë¡œë“œ (BM25ë¥¼ ìœ„í•´ í•„ìš”)
    all_docs = vectorstore.get()
    
    if not all_docs or not all_docs.get('documents'):
        raise ValueError("VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    documents = []
    for i, doc_text in enumerate(all_docs['documents']):
        if doc_text and doc_text.strip():
            metadata = all_docs['metadatas'][i] if 'metadatas' in all_docs else {}
            documents.append(Document(page_content=doc_text, metadata=metadata))
    
    # RAG íŒŒì´í”„ë¼ì¸ ìƒì„±
    rag = AdvancedRAGPipeline(
        documents=documents,
        vectorstore=vectorstore,
        llm=llm,
        enable_router=True,
        enable_multi_query=True,
        enable_ensemble=True,
        enable_rrf=True,
        enable_memory=True,
        enable_region_filter=True,
        bm25_k=5,
        vector_k=10,
        bm25_weight=0.4,
        vector_weight=0.6
    )
    
    return rag