import json
import os
import warnings
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field 
from datetime import datetime

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_chroma import Chroma
from langchain_core.output_parsers import StrOutputParser

from dotenv import load_dotenv
load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

try:
    with warnings.catch_warnings():
        warnings.filterwarnings('ignore', category=DeprecationWarning)
        from langchain_community.retrievers import BM25Retriever, EnsembleRetriever
    RETRIEVERS_AVAILABLE = True
except ImportError:
    RETRIEVERS_AVAILABLE = False
    BM25Retriever = None
    EnsembleRetriever = None

# ============================================================================
# 1. ì§€ì—­ ì •ê·œí™”
class RegionNormalizer:
    def __init__(self, regions_data: List[Dict]):
        self.code_to_info = {}
        self.name_to_codes = {}
  
        self.sido_aliases = {
            "ì„œìš¸": "ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°": "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
            "ì¸ì²œ": "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼": "ê´‘ì£¼ê´‘ì—­ì‹œ", "ëŒ€ì „": "ëŒ€ì „ê´‘ì—­ì‹œ",
            "ìš¸ì‚°": "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°": "ê²½ê¸°ë„",
            "ì¶©ë¶": "ì¶©ì²­ë¶ë„", "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„", "ì „ë¶": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
            "ì „ë‚¨": "ì „ë¼ë‚¨ë„", "ê²½ë¶": "ê²½ìƒë¶ë„", "ê²½ë‚¨": "ê²½ìƒë‚¨ë„",
            "ì œì£¼": "ì œì£¼íŠ¹ë³„ìì¹˜ë„", "ê°•ì›": "ê°•ì›íŠ¹ë³„ìì¹˜ë„"
        }

        self.national_keywords = ["ì „êµ­", "ëŒ€í•œë¯¼êµ­", "ì •ë¶€", "êµ­ê°€", "ì „ì²´", "ëª¨ë“ ", "ëª¨ë‘"]
        
        self._build_maps(regions_data)

    def _build_maps(self, regions_data: List[Dict]):
        """ë¦¬ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  ë”•ì…”ë„ˆë¦¬ë¥¼ ìˆœíšŒí•˜ë©° ë§ˆìŠ¤í„° ì‚¬ì „ êµ¬ì¶•"""
        for region_group in regions_data:
            for code, info in region_group.items():
                self.code_to_info[code] = info
                sido = info.get('ì‹œë„', '')
                sigungu = info.get('ì‹œêµ°êµ¬', '')


                if sido:
                    self._add_to_map(sido, code)
                    for alias, full in self.sido_aliases.items():
                        if full == sido:
                            self._add_to_map(alias, code)
                
                if sigungu:
                    self._add_to_map(sigungu, code)
                    self._add_to_map(sigungu.replace(" ", ""), code) 

                    parts = sigungu.split(" ")
                    last_part = parts[-1] 
                    self._add_to_map(last_part, code)
                    
                    if len(last_part) > 1: 
                        self._add_to_map(last_part[:-1], code)

    def _add_to_map(self, name: str, code: str):
        if not name or len(name) < 1: return
        if name not in self.name_to_codes: self.name_to_codes[name] = []
        if code not in self.name_to_codes[name]: self.name_to_codes[name].append(code)

    def detect(self, query: str) -> Dict:
        """ì§ˆë¬¸ì—ì„œ ì „êµ­ í‚¤ì›Œë“œ ë° ì§€ì—­ ì½”ë“œ ì¶”ì¶œ"""
        is_national = any(kw in query for kw in self.national_keywords)
        
        detected_sido_codes = []
        for alias in self.sido_aliases.keys():
            if alias in query:
                detected_sido_codes.extend(self.name_to_codes.get(alias, []))

        detected_code = None
        found_name = None
        sorted_names = sorted(self.name_to_codes.keys(), key=len, reverse=True)
        
        for name in sorted_names:
            if name in query:
                possible_codes = self.name_to_codes[name]
                # ì¤‘ë³µ ì§€ëª… ì²˜ë¦¬
                if len(possible_codes) > 1 and detected_sido_codes:
                    for c in possible_codes:
                        if any(self.code_to_info[c]['ì‹œë„'] == self.code_to_info[s]['ì‹œë„'] for s in detected_sido_codes):
                            detected_code = c
                            break
                if not detected_code:
                    detected_code = possible_codes[0]
                found_name = name
                break

        res_sido = None
        res_sigungu = None
        if detected_code:
            info = self.code_to_info[detected_code]
            if info.get('ì‹œêµ°êµ¬'):
                res_sigungu = detected_code
                for c, i in self.code_to_info.items():
                    if i['ì‹œë„'] == info['ì‹œë„'] and not i['ì‹œêµ°êµ¬']:
                        res_sido = c
                        break
            else:
                res_sido = detected_code

        return {
            "has_region": bool(res_sido or res_sigungu or is_national),
            "sido_code": res_sido,
            "sigungu_code": res_sigungu,
            "is_national": is_national, # ì „êµ­ ì—¬ë¶€ ë°˜í™˜
            "detected_name": found_name
        }

# 2. RegionFilter: ì½”ë“œ ê¸°ë°˜
class RegionFilter:
    def __init__(self, regions_data: List[Dict]):
        self.normalizer = RegionNormalizer(regions_data)

    def build_chroma_filter_from_codes(self, region_info: Dict) -> Optional[Dict]:
        filter_conditions = [{"region_scope": "national"}] 
        
        if region_info.get('sigungu_code'):
            filter_conditions.append({"regiona_code.sigungu": {"$array_contains": region_info['sigungu_code']}})
        
        if region_info.get('sido_code'):
            filter_conditions.append({"regions_code.sido": {"$array_contains": region_info['sido_code']}})
            
        return {"$or": filter_conditions}
    
    def build_chroma_filter_from_codes(self, region_info: Dict) -> Optional[Dict]:
        """ì§€ì—­ ì •ë³´ ë”•ì…”ë„ˆë¦¬ë¡œë¶€í„° ChromaDB í•„í„° ìƒì„±"""
        if region_info.get('is_national'):
            return {"region_scope": "national"}
        
        if not region_info.get('sido_code') and not region_info.get('sigungu_code'):
            return None

        filter_conditions = [{"region_scope": "national"}]
        
        detected_code = region_info.get('sigungu_code') or region_info.get('sido_code')
        if detected_code:
            # JSON ë¬¸ìì—´ì— ì½”ë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            # ì˜ˆ: "[\"11110\", \"11111\"]" contains "11110"
            filter_conditions.append({"regions_code.sido": {"$contains": detected_code}})
            filter_conditions.append({"regiona_code.sigungu": {"$contains": detected_code}})
        
        return {"$or": filter_conditions} if filter_conditions else None

    def post_filter(self, documents: List, detected_code: Optional[str]) -> List:
        if not detected_code: 
            return documents
        
        filtered = []
        for doc in documents:
            # ì „êµ­ ì •ì±… íŒ¨ìŠ¤ (ëª¨ë“  ì§€ì—­ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
            if doc.metadata.get('region_scope') == 'national':
                filtered.append(doc)
                continue
            
            # ì§€ì—­ ì •ì±…ì˜ ê²½ìš° - ì •í™•í•œ ì½”ë“œ ë§¤ì¹­ë§Œ í—ˆìš©
            sido_json = doc.metadata.get('regions_code.sido', '[]')
            sigungu_json = doc.metadata.get('regiona_code.sigungu', '[]')
            
            try:
                doc_sido = json.loads(sido_json) if isinstance(sido_json, str) else sido_json
                doc_sigungu = json.loads(sigungu_json) if isinstance(sigungu_json, str) else sigungu_json
            except:
                doc_sido = []
                doc_sigungu = []
            
            if not isinstance(doc_sido, list):
                doc_sido = [doc_sido] if doc_sido else []
            if not isinstance(doc_sigungu, list):
                doc_sigungu = [doc_sigungu] if doc_sigungu else []
            
            # ì •í™•í•œ ì½”ë“œ ë§¤ì¹­ í™•ì¸
            if detected_code in doc_sido or detected_code in doc_sigungu:
                filtered.append(doc)
        
        # í•„í„°ë§ í›„ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì „êµ­ ì •ì±…ë§Œ ë°˜í™˜
        return filtered if filtered else [d for d in documents if d.metadata.get('region_scope') == 'national']
    
# 3. ë¼ìš°í„°
import json
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

class QueryRouter:
    """ì‚¬ìš©ì ì§ˆë¬¸ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•˜ê³  ê²€ìƒ‰ìš© í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ë¼ìš°í„°"""
    
    def __init__(self, llm):
        self.llm = llm
        self.router_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ì±—ë´‡ì˜ 'ì…ë ¥ ë¶„ì„ê°€'ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ 1) ìœ íš¨ì„±ì„ íŒë‹¨í•˜ê³ , 2) ê²€ìƒ‰ì— ë°©í•´ë˜ëŠ” ì§€ì—­ëª…ì„ ì œê±°í•œ 'ìˆœìˆ˜ ì£¼ì œ í‚¤ì›Œë“œ'ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.

[ì‘ì—… 1: ìœ íš¨ì„± ê²€ì¦ (is_valid)]
- False ì¡°ê±´: ì‹¬í•œ ìš•ì„¤, ë¹„ì†ì–´, ë¬´ì˜ë¯¸í•œ ìëª¨ìŒ ë‚˜ì—´(ì˜ˆ: 'ã…‹ã…‹ã…‹', 'ã„´ã…‡ã„¹', 'asdf'), ì •ì±…ê³¼ ì „í˜€ ë¬´ê´€í•œ í˜ì˜¤ í‘œí˜„
- True ì¡°ê±´: ì¸ì‚¿ë§(ì•ˆë…•), ë‹¨ìˆœ ì§€ì—­ëª…(ë¶€ì‚°), ì§§ì€ í‚¤ì›Œë“œ(ì°½ì—…, ì£¼ê±°ì§€ì›), ë¬¸ì¥í˜• ì§ˆë¬¸ ë“± ì •ìƒì ì¸ ëŒ€í™” ì‹œë„

[ì‘ì—… 2: í‚¤ì›Œë“œ ì •ì œ (refined_query)]
- ì§ˆë¬¸ì—ì„œ **ì§€ì—­ëª…(ì‹œë„, ì‹œêµ°êµ¬)**ê³¼ **ì¡°ì‚¬(ì€/ëŠ”/ì´/ê°€)**, **ìˆ˜ì‹ì–´(ì „êµ­, ì „ì²´)**ë¥¼ ì œê±°í•˜ì„¸ìš”.
- ì˜¤ì§ **'ì–´ë–¤ ì •ì±…ì„ ì°¾ê³  ì‹¶ì€ì§€'**ì— ëŒ€í•œ í•µì‹¬ ëª…ì‚¬(í‚¤ì›Œë“œ)ë§Œ ë‚¨ê¸°ì„¸ìš”.
- ë§Œì•½ ì§€ì—­ëª…ë§Œ ìˆê³  í‚¤ì›Œë“œê°€ ì—†ë‹¤ë©´(ì˜ˆ: "ë¶€ì‚°"), "ì²­ë…„ ì •ì±…"ì´ë¼ê³  ë°˜í™˜í•˜ì„¸ìš”.

[Few-shot ì˜ˆì‹œ]
- ì…ë ¥: "ê²½ê¸°ë„ ë´‰ì‚¬" -> refined_query: "ë´‰ì‚¬" (ì§€ì—­ëª… 'ê²½ê¸°ë„' ì œê±°)
- ì…ë ¥: "ë¶€ì‚° ìê²©ì¦ ì§€ì›" -> refined_query: "ìê²©ì¦ ì§€ì›" (ì§€ì—­ëª… 'ë¶€ì‚°' ì œê±°)
- ì…ë ¥: "ì„œìš¸ì‹œ ì£¼ê±°" -> refined_query: "ì£¼ê±°"
- ì…ë ¥: "ì „êµ­ ì¼ìë¦¬ ì„¼í„°" -> refined_query: "ì¼ìë¦¬ ì„¼í„°"
- ì…ë ¥: "ê°œXXì•¼ êº¼ì ¸" -> is_valid: false, reason: "ìš•ì„¤ ë° ë¹„ì†ì–´ ê°ì§€"
- ì…ë ¥: "asdfasdf" -> is_valid: false, reason: "ë¬´ì˜ë¯¸í•œ ë¬¸ìì—´"

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "is_valid": true/false,
    "refined_query": "ì •ì œëœ í‚¤ì›Œë“œ",
    "reason": "íŒë‹¨ ê·¼ê±°"
}}"""),
            ("user", "{query}")
        ])
    
    def route(self, query: str) -> dict:
        """ì§ˆë¬¸ ê²€ì¦ ë° í•µì‹¬ í‚¤ì›Œë“œ ë°˜í™˜"""
        try:
            chain = self.router_prompt | self.llm | StrOutputParser()
            result_str = chain.invoke({"query": query})
  
            cleaned_str = result_str.strip().replace("```json", "").replace("```", "")

            result = json.loads(cleaned_str)
            return result
            
        except json.JSONDecodeError:
            logger.warning(f"[QueryRouter] JSON íŒŒì‹± ì—ëŸ¬. ì›ë³¸: {result_str}")
            return {
                "is_valid": True,
                "refined_query": query, # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
                "reason": "íŒŒì‹± ì—ëŸ¬ë¡œ ì¸í•œ ê¸°ë³¸ ì²˜ë¦¬"
            }
        except Exception as e:
            logger.exception(f"[QueryRouter] ì—ëŸ¬ ë°œìƒ: {e}")
            return {
                "is_valid": True,
                "refined_query": query,
                "reason": "ì‹œìŠ¤í…œ ì—ëŸ¬ë¡œ ì¸í•œ ê¸°ë³¸ ì²˜ë¦¬"
            }

# 4. ë©€í‹°ì¿¼ë¦¬        
class MultiQueryGenerator:
    """ê²€ìƒ‰ ì¬í˜„ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ ì§ˆë¬¸ì„ ë‹¤ê°ë„ë¡œ í™•ì¥"""
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì²­ë…„ ì •ì±… ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ë²¡í„° DB ê²€ìƒ‰ì— ìµœì í™”ëœ 3ê°œì˜ ìœ ì‚¬ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”.
ë‹¨, ì›ë³¸ì˜ í•µì‹¬ ì˜ë¯¸(ì°½ì—…, ì£¼ê±° ë“±)ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë‹¤ì–‘í•œ í‚¤ì›Œë“œ(í”Œë«í¼, ì§€ì›ê¸ˆ, ì„¼í„° ë“±)ë¥¼ í™œìš©í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
1. í™•ì¥ ì§ˆë¬¸ 1
2. í™•ì¥ ì§ˆë¬¸ 2
3. í™•ì¥ ì§ˆë¬¸ 3"""),
            ("user", "{query}")
        ])

    def generate(self, query: str) -> List[str]:
        chain = self.prompt | self.llm | StrOutputParser()
        response = chain.invoke({"query": query})
        # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸í™”
        queries = [q.strip() for q in response.split("\n") if q.strip()]
        return queries[:3]


# 5. ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„
class EnsembleRetriever:
    """
    Dense(ì˜ë¯¸) ê²€ìƒ‰ê³¼ BM25(í‚¤ì›Œë“œ) ê²€ìƒ‰ì„ ê²°í•©í•œ í†µí•© ë¦¬íŠ¸ë¦¬ë²„
    - QueryRouterê°€ ë½‘ì•„ì¤€ 'í•µì‹¬ í‚¤ì›Œë“œ'ë¡œ ê²€ìƒ‰ ìˆ˜í–‰
    - RegionFilterê°€ ìƒì„±í•œ 'í–‰ì • ì½”ë“œ í•„í„°' ì ìš©
    """
    
    def __init__(
        self, 
        documents: List[any],
        vectorstore: Chroma,
        llm: ChatOpenAI = None,
        bm25_k: int = 15,       # ê²€ìƒ‰ ì¬í˜„ìœ¨(Recall)ì„ ìœ„í•´ Kê°’ ìƒí–¥ (ê¸°ì¡´ 5)
        vector_k: int = 20,     # ì „êµ­ ì •ì±… í™•ë³´ë¥¼ ìœ„í•´ Kê°’ ìƒí–¥ (ê¸°ì¡´ 10)
        bm25_weight: float = 0.6,   # 'ì¤‘ë…' ë“± í•µì‹¬ í‚¤ì›Œë“œ ë³´ì¡´ì„ ìœ„í•´ ë¹„ì¤‘ ìƒí–¥ (ê¸°ì¡´ 0.4)
        vector_weight: float = 0.4  # ì˜ë¯¸ì  ì™œê³¡(ì¶•ì œ ë“±) ë°©ì§€ë¥¼ ìœ„í•´ ë¹„ì¤‘ ì¡°ì • (ê¸°ì¡´ 0.6)
    ):
        self.documents = documents
        self.vectorstore = vectorstore
        self.llm = llm
        
        self.bm25_k = bm25_k
        self.vector_k = vector_k
        self.bm25_weight = bm25_weight
        self.vector_weight = vector_weight
        
        self._build_bm25()
        self._build_vector()
    
    def _build_bm25(self):
        """í‚¤ì›Œë“œ ê¸°ë°˜ BM25 ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”"""
        if not RETRIEVERS_AVAILABLE or BM25Retriever is None or not self.documents:
            self.bm25_retriever = None
            return
        
        try:
            self.bm25_retriever = BM25Retriever.from_documents(
                documents=self.documents,
                k=self.bm25_k
            )
        except Exception:
            self.bm25_retriever = None
    
    def _build_vector(self):
        """ì„ë² ë”© ê¸°ë°˜ Vector ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”"""
        try:
            # ê¸°ë³¸ ë¦¬íŠ¸ë¦¬ë²„ë¡œ ì„¤ì •í•˜ë˜ ê²€ìƒ‰ ì‹œ kê°’ ì ìš©
            self.vector_retriever = self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": self.vector_k}
            )
        except Exception:
            self.vector_retriever = None
    
    def dense_search(self, query: str, metadata_filter: Dict = None) -> List[Tuple[any, float]]:
        """
        í–‰ì • ì½”ë“œ í•„í„°ê°€ ì ìš©ëœ Dense ê²€ìƒ‰
        - query: QueryRouterê°€ ì •ì œí•œ refined_query
        - metadata_filter: RegionFilterê°€ ë§Œë“  ì½”ë“œ ê¸°ë°˜ í•„í„° ($or ì¡°ê±´ ë“±)
        """
        try:
            if self.vector_retriever:
                # ë©”íƒ€ë°ì´í„° í•„í„°(ì‹œë„/ì‹œêµ°êµ¬ ì½”ë“œ)ë¥¼ ì ìš©í•˜ì—¬ ì •ë°€ ê²€ìƒ‰
                docs = self.vectorstore.similarity_search(
                    query, 
                    k=self.vector_k,
                    filter=metadata_filter
                )
                return [(doc, 1.0) for doc in docs]
            return []
        except Exception:
            return []
    
    def bm25_search(self, query: str) -> List[Tuple[any, float]]:
        """í‚¤ì›Œë“œ(ëª…ì‚¬) ê¸°ë°˜ ê²€ìƒ‰ - ì •ì±… ê³ ìœ ëª…ì‚¬ í¬ì°©ìš©"""
        try:
            if self.bm25_retriever:
                docs = self.bm25_retriever.invoke(query)
                return [(doc, 1.0) for doc in docs]
            return []
        except Exception:
            return []
    
    def retrieve(self, queries: List[str], metadata_filter: Dict = None) -> Dict[str, List[Tuple[any, float]]]:
        """
        ë©€í‹° ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ RRFë¡œ ë„˜ê²¨ì£¼ê¸° ìœ„í•œ í†µí•© ê²€ìƒ‰ ì‹¤í–‰
        """
        all_results = {
            'dense': [],
            'bm25': []
        }
        
        for q in queries:
            # ê° ì¿¼ë¦¬ë‹¹ Dense ê²€ìƒ‰(í•„í„° í¬í•¨)ê³¼ BM25 ê²€ìƒ‰ ìˆ˜í–‰
            all_results['dense'].extend(self.dense_search(q, metadata_filter))
            all_results['bm25'].extend(self.bm25_search(q))
        
        return all_results
    
# 6. RRF
class ReciprocalRankFusion:
    """
    ì—¬ëŸ¬ ê²€ìƒ‰ ì „ëµ(Dense, BM25)ì˜ ê²°ê³¼ë¥¼ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ í†µí•©í•˜ê³ ,
    ì „êµ­ ë‹¨ìœ„ ì •ì±…ì— ê°€ì‚°ì ì„ ë¶€ì—¬í•˜ì—¬ ìƒìœ„ê¶Œìœ¼ë¡œ ìœ ì§€í•˜ëŠ” í†µí•© ì—”ì§„
    """
    
    def __init__(self, k: int = 60):
        self.k = k  
    
    def fuse(self, results_dict: Dict[str, List[Tuple[any, float]]], top_k: int = 20) -> List[any]:
        """
        ê²€ìƒ‰ ê²°ê³¼ í†µí•© ë° ì „êµ­ ì •ì±… ë¶€ìŠ¤íŒ…
        - results_dict: {'dense': [(doc, score), ...], 'bm25': [...]}
        - top_k: ìµœì¢…ì ìœ¼ë¡œ LLMì—ê²Œ ì „ë‹¬í•  ë¬¸ì„œ ìˆ˜ (ì¶©ë¶„í•œ í›„ë³´ í™•ë³´ë¥¼ ìœ„í•´ ìƒí–¥ ê¶Œì¥)
        """
        doc_scores = {}
        
        # 1. ê° ê²€ìƒ‰ ë°©ì‹ë³„ ê²°ê³¼ ìˆœíšŒ
        for method, results in results_dict.items():
            for rank, (doc, _) in enumerate(results, 1):
                # ë¬¸ì„œ ì‹ë³„ì ì¶”ì¶œ (ì •ì±…ëª… ë˜ëŠ” ê³ ìœ  ID ì‚¬ìš©)
                # ìš°ë¦¬ ì •ê·œí™” ë°ì´í„°ì˜ 'ì •ì±…ëª…' ë˜ëŠ” 'policy_id'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•¨
                doc_id = doc.metadata.get('ì •ì±…ëª…', id(doc))
                
                # RRF í•µì‹¬ ê³µì‹ ì ìš©: 1 / (k + rank)
                rrf_score = 1.0 / (self.k + rank)
                
                if doc_id not in doc_scores:
                    doc_scores[doc_id] = {'doc': doc, 'score': 0}
                
                # ì ìˆ˜ ëˆ„ì  (Denseì™€ BM25 ëª¨ë‘ì—ì„œ ìƒìœ„ê¶Œì¸ ë¬¸ì„œê°€ ë†’ì€ ì ìˆ˜ë¥¼ ì–»ìŒ)
                doc_scores[doc_id]['score'] += rrf_score
        
        # 2. ì „êµ­ ë‹¨ìœ„ ì •ì±… ë¶€ìŠ¤íŒ…
        # íŠ¹ì • ì§€ì—­ ê²€ìƒ‰ ì‹œ ì§€ì—­ ì •ì±…ì— ë°€ë ¤ ì‚¬ë¼ì§€ëŠ” ì „êµ­ ë‹¨ìœ„ í•µì‹¬ ì •ì±…ì„ ëŒì–´ì˜¬ë¦¼
        for doc_id in doc_scores:
            doc = doc_scores[doc_id]['doc']
            # ë°ì´í„° ì •ê·œí™” ë•Œ ì„¤ì •í•œ 'region_scope' í™œìš©
            if doc.metadata.get('region_scope') == 'national':
                # ì „êµ­ ì •ì±…ì— ì•½ 20%ì˜ ê°€ì‚°ì ì„ ì£¼ì–´ ì§€ì—­ ì •ì±… ì‚¬ì´ì‚¬ì´ì— ì„ì´ê²Œ í•¨
                doc_scores[doc_id]['score'] *= 1.2
        
        # 3. ìµœì¢… ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_docs = sorted(
            doc_scores.items(), 
            key=lambda x: x[1]['score'], 
            reverse=True
        )
        
        # 4. ìƒìœ„ top_kê°œ ë¬¸ì„œ ë°˜í™˜
        final_docs = [item[1]['doc'] for item in sorted_docs[:top_k]]
        
        return final_docs

# 7. ë©”ëª¨ë¦¬
@dataclass
class ConversationMemory:
    """ëŒ€í™” ê¸°ë¡ ë° ì‚¬ìš©ìì˜ ì§€ì—­ ë§¥ë½(Context) ê´€ë¦¬"""
    messages: List[Dict] = field(default_factory=list)
    max_history: int = 10
    current_region: Dict = field(default_factory=lambda: {
        "sido_code": None, 
        "sigungu_code": None, 
        "is_national": False
    })
    
    def add_message(self, role: str, content: str, region_info: Optional[Dict] = None):
        """ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•  ë•Œ ê°ì§€ëœ ì§€ì—­ ì •ë³´ë„ ì—…ë°ì´íŠ¸"""
        self.messages.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # [ìˆ˜ì •] ìƒˆë¡œìš´ ì§€ì—­ ì •ë³´ê°€ ë“¤ì–´ì˜¤ë©´ ì—…ë°ì´íŠ¸ (ê¸°ì–µ ìœ ì§€)
        if region_info and region_info.get('has_region'):
            self.current_region = {
                "sido_code": region_info.get('sido_code'),
                "sigungu_code": region_info.get('sigungu_code'),
                "is_national": region_info.get('is_national', False)
            }
        
        if len(self.messages) > self.max_history * 2:
            self.messages = self.messages[-self.max_history * 2:]
    
    def get_context(self) -> str:
        """LLM ë‹µë³€ ìƒì„±ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ë§¥ë½ ìƒì„±"""
        if not self.messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"
        
        context_parts = []
        for msg in self.messages[-6:]:  # ìµœê·¼ 3í„´
            role = "ì‚¬ìš©ì" if msg['role'] == 'user' else "AI"
            context_parts.append(f"{role}: {msg['content']}")
        
        return "\n".join(context_parts)

    def get_region_context(self) -> Dict:
        """í˜„ì¬ ê¸°ì–µí•˜ê³  ìˆëŠ” ì§€ì—­ ì •ë³´ ë°˜í™˜"""
        return self.current_region
    
    def clear(self):
        """ê¸°ë¡ ë° ì§€ì—­ ì •ë³´ ì´ˆê¸°í™”"""
        self.messages.clear()
        self.current_region = {"sido_code": None, "sigungu_code": None, "is_national": False}


# 8. ìµœì¢… íŒŒì´í”„ë¼ì¸
class AdvancedRAGPipeline:

    def __init__(
        self,
        vectorstore,  # vectordb2
        regions_data: List[Dict],  # regions_code.json ë°ì´í„°
        llm,
        documents: List[any]  # BM25ìš© ì „ì²´ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
    ):
        # 1. ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.router = QueryRouter(llm)
        self.multi_query = MultiQueryGenerator(llm) 
        self.region_filter = RegionFilter(regions_data)
        self.retriever = EnsembleRetriever(
            documents=documents,
            vectorstore=vectorstore,
            llm=llm
        )
        self.rrf = ReciprocalRankFusion()
        self.memory = ConversationMemory()
        self.llm = llm

        # 2. ë‹µë³€ ìƒì„±ìš© ì„ ë°°ë´‡ í”„ë¡¬í”„íŠ¸
        self.answer_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ 'ì˜¨í†µì²­ë…„ ì²­ë…„ì •ì±… ì „ë‹´ ì±—ë´‡ ì„ ë°°ë´‡'ì…ë‹ˆë‹¤.

ì—­í• :
- ë„ˆëŠ” ì²­ë…„ ì •ì±…(íŠ¹íˆ ì£¼ê±°Â·ì›”ì„¸Â·ì¼ìë¦¬Â·ë³µì§€) ì •ë³´ë¥¼, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ì •ë¦¬í•´ ì£¼ëŠ” ì„ ë°°ì•¼.
- í›„ë°°ì—ê²Œ ì•Œë ¤ì£¼ë“¯ ì¹œê·¼í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ ë‹µë³€í•´. (ì˜ˆ: ~í•´ì¤„ê²Œ, ~í•´ë³´ì, ~ì´ì•¼)
- ë°˜ë“œì‹œ 'ê²€ìƒ‰ëœ ì •ì±… ì •ë³´(documents)' ì•ˆì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•´ì„œ ë‹µë³€í•´.
- ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ê³ , ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì´ë¼ í™•ë‹µì´ ì–´ë µë‹¤"ê³  ë§í•´.
- ê° ì •ì±…ì˜ ë§ˆì§€ë§‰ 'ì‹ ì²­ ë°©ë²•' í•­ëª©ì— ë°˜ë“œì‹œ ì œê³µëœ 'ì°¸ê³  URL'ì„ í¬í•¨í•´ì¤˜.

ì¶œë ¥ í˜•ì‹(ê¼­ ì§€ì¼œì•¼ í•¨):

1. ì²« ì¤„ì— ì§ˆë¬¸ì„ ìš”ì•½í•˜ëŠ” í•œ ë¬¸ì¥ì„ ì“´ë‹¤.
    1-1. ë§íˆ¬ë¥¼ ëƒ¥ëƒ¥ì²´ë¡œ ë°”ê¾¼ë‹¤. (ì˜ˆ: ~ëƒ¥, ~í•´ì¤„ê²Œëƒ¥)
2. ê·¸ ë‹¤ìŒì— ì •ì±…ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ ì •ë¦¬í•œë‹¤.
   - ê·¸ ë‹¤ìŒì— ì •ì±…ì„ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ì„œ ì •ë¦¬í•œë‹¤. (3~5ê°œ)
   - ê° ì •ì±…ì€ ì•„ë˜ êµ¬ì¡°ë¥¼ ë”°ë¥¸ë‹¤.

   ì˜ˆì‹œ í˜•ì‹:

   1. ì •ì±…ëª…  
    ğŸ”¸ì‚¬ì—… ê°œìš”
        - ì‚¬ì—… ê¸°ê°„ : ...
        - ëª©ì  : ...

    ğŸ”¸ì‹ ì²­ ìê²©
        - ì—°ë ¹ : ...
        - ì£¼ê±° : ...
        - ì†Œë“ : ...
        - ê¸°íƒ€ ì¡°ê±´ : ...

    ğŸ”¸ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„
        - ì›” ì§€ì› ê¸ˆì•¡ : ...
        - ì§€ì› ê¸°ê°„ : ...

    ğŸ”¸ì‹ ì²­ ë°©ë²•
        - ì–´ë””ì— ì‹ ì²­ : ...
        - ì–´ë–»ê²Œ ì‹ ì²­ : ...
        - ì°¸ê³ URL: (ì œê³µëœ ì°¸ê³  URLì„ ì—¬ê¸°ì— ê¸°ì¬, ì—†ìœ¼ë©´ 'ê³µê³ ë¬¸ ì°¸ì¡°'ë¼ê³  ì‘ì„±)
             
    
   2. ì •ì±…ëª…  
    ğŸ”¸ì‚¬ì—… ê°œìš”
        - ì‚¬ì—… ê¸°ê°„ : ...
        - ëª©ì  : ...

    ğŸ”¸ì‹ ì²­ ìê²©
        - ì—°ë ¹ : ...
        - ì£¼ê±° : ...
        - ì†Œë“ : ...
        - ê¸°íƒ€ ì¡°ê±´ : ...

    ğŸ”¸ì§€ì› ê¸ˆì•¡Â·ê¸°ê°„
        - ì›” ì§€ì› ê¸ˆì•¡ : ...
        - ì§€ì› ê¸°ê°„ : ...

    ğŸ”¸ì‹ ì²­ ë°©ë²•
        - ì–´ë””ì— ì‹ ì²­ : ...
        - ì–´ë–»ê²Œ ì‹ ì²­ : ...
        - ì°¸ê³ URL: ë°˜ë“œì‹œ ê° ì •ì±…ì˜ 'ì°¸ê³ URL1' í•„ë“œ ê°’ì„ ê·¸ëŒ€ë¡œ í‘œê¸°í•  ê²ƒ (ì˜ˆ: ì°¸ê³ URL: https://...)
   3. ...
             
    3. ë§ˆì§€ë§‰ì— 'ì¶œì²˜' ë¸”ë¡ì„ ì ëŠ”ë‹¤.
    - ë¬¸ì„œ ë©”íƒ€ë°ì´í„°(íŒŒì¼ëª…, í˜ì´ì§€ ì •ë³´ ë“±)ê°€ ìˆìœ¼ë©´ ìµœëŒ€í•œ í™œìš©í•´ì„œ ì‘ì„±í•œë‹¤.
    - ì˜ˆì‹œ:
    ğŸ”¹ ì¶œì²˜:
        - ì˜¨í†µì²­ë…„ ì²­ë…„ì •ì±… í¬í„¸ (https://youthcenter.go.kr)

ì‘ì„± ì‹œ ìœ ì˜ì‚¬í•­:
- ì •ì±…ëª…ì´ ê°™ì€ ê²ƒì„ ì¤‘ë³µí•´ì„œ ì“°ì§€ ë§ ê²ƒ.
- ì§ˆë¬¸ì—ì„œ ì–¸ê¸‰í•œ ì§€ì—­(ì˜ˆ: ê²½ë¶, ëŒ€êµ¬ ë“±)ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ” ì •ì±…ì„ ìµœìš°ì„ ìœ¼ë¡œ ì„ íƒí•  ê²ƒ.
- ì§ˆë¬¸ì—ì„œ 'ì›”ì„¸', 'ë³´ì¦ê¸ˆ', 'ì „ì„¸' ë“± í‚¤ì›Œë“œê°€ ë‚˜ì˜¤ë©´, ì£¼ê±°Â·ì›”ì„¸ ê´€ë ¨ ì •ì±… ìœ„ì£¼ë¡œ ì •ë¦¬í•  ê²ƒ.
- ìˆ«ì(ì§€ì› ê¸ˆì•¡, ê¸°ê°„, ì—°ë ¹)ëŠ” ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ê°’ìœ¼ë¡œ ì¨ ì¤„ ê²ƒ.
- ì¤„ë°”ê¿ˆì´ë‚˜ ë¬¸ë‹¨ êµ¬ë¶„ì„ ëª…í™•íˆ í•´ì„œ ê°€ë…ì„±ì„ ë†’ì¼ ê²ƒ.

"""),
            ("user", """[ëŒ€í™” ë§¥ë½]
{context}

[ê²€ìƒ‰ëœ ì •ì±… ì •ë³´]
{documents}

[í˜„ì¬ ì§ˆë¬¸]
{query}""")
        ])

    def query(self, user_query: str) -> Dict:
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (ë©€í‹°ì¿¼ë¦¬ í™•ì¥ ë° ì§€ì—­ í•„í„°ë§ ì ìš©)"""
        
        # [Step 1] ì§€ì—­ ê°ì§€ ìš°ì„  ìˆ˜í–‰
        current_region_info = self.region_filter.normalizer.detect(user_query)
        logger.debug(f"ê°ì§€ëœ ì§€ì—­ ì •ë³´: {current_region_info}")
        
        # ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ë° í˜„ì¬ ì§€ì—­ ë§¥ë½ ìœ ì§€
        self.memory.add_message("user", user_query, current_region_info)
        active_region_info = self.memory.get_region_context()

        # [Step 2] Router ê²€ì¦
        route_result = self.router.route(user_query)
        logger.debug(f"Router ê²°ê³¼: {route_result}")
        
        if not route_result['is_valid']:
            return {
                "answer": "ì•ˆë…•! 'ì„œìš¸, ìê²©ì¦'ì´ë‚˜ 'ì„œìš¸ ê°•ë‚¨êµ¬ ì¼ìë¦¬'ì²˜ëŸ¼ êµ¬ì²´ì ìœ¼ë¡œ ë¬¼ì–´ë´ì£¼ë©´ ë‚´ê°€ ì •ì±…ì„ ë” ì˜ ì°¾ì•„ì¤„ ìˆ˜ ìˆì–´!ğŸ˜Š",
                "detected_region": active_region_info,
                "source_documents": []
            }
        
        refined_keyword = route_result['refined_query']
        logger.debug(f"ì •ì œëœ í‚¤ì›Œë“œ: {refined_keyword}")

        # [Step 2-1 ì¶”ê°€] ë©€í‹°ì¿¼ë¦¬ í™•ì¥
        # "ì°½ì—… ì§€ì›" -> ["ì²­ë…„ ì°½ì—… í”Œë«í¼", "ì°½ì—… ì§€ì›ê¸ˆ ì‹ ì²­", "ìŠ¤íƒ€íŠ¸ì—… ì§€ì› ì„¼í„°"]
        expanded_queries = self.multi_query.generate(refined_keyword)
        all_queries = [refined_keyword] + expanded_queries
        logger.debug(f"ìƒì„±ëœ ë©€í‹°ì¿¼ë¦¬: {all_queries}")

        # [Step 3] í•„í„° ìƒì„±
        db_filter = None
        detected_region_code = None
        
        if not active_region_info.get('is_national') and (active_region_info.get('sigungu_code') or active_region_info.get('sido_code')):
            detected_region_code = active_region_info.get('sigungu_code') or active_region_info.get('sido_code')
            db_filter = self.region_filter.build_chroma_filter_from_codes(active_region_info)
            logger.debug(f"ì§€ì—­ ì½”ë“œ ê°ì§€ë¨: {detected_region_code}")
        
        logger.debug(f"ìƒì„±ëœ í•„í„°: {db_filter}")

        # [Step 4 ìˆ˜ì •] Retrieval: ì•™ìƒë¸” ê²€ìƒ‰ (ë©€í‹°ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬)
        search_results = self.retriever.retrieve(all_queries, db_filter)
        logger.debug(f"ê²€ìƒ‰ ê²°ê³¼ (Dense): {len(search_results['dense'])}, BM25: {len(search_results['bm25'])}")

        # [Step 5] RRF & Boosting
        top_docs = self.rrf.fuse(search_results, top_k=20)
        logger.debug(f"RRF í›„ ë¬¸ì„œ ìˆ˜: {len(top_docs)}")

        # [Step 6 ìˆ˜ì •] ë¬¸ì„œê°€ ì—†ìœ¼ë©´ í•„í„° ì—†ì´ ë©€í‹°ì¿¼ë¦¬ë¡œ ì¬ê²€ìƒ‰
        if not top_docs:
            logger.debug("í•„í„°ë§ëœ ë¬¸ì„œ ì—†ìŒ. í•„í„° ì œê±° í›„ ì¬ê²€ìƒ‰...")
            search_results = self.retriever.retrieve(all_queries, None)
            logger.debug(f"í•„í„° ì œê±° í›„ ê²€ìƒ‰ ê²°ê³¼ (Dense): {len(search_results['dense'])}, BM25: {len(search_results['bm25'])}")
            top_docs = self.rrf.fuse(search_results, top_k=20)
            logger.debug(f"í•„í„° ì œê±° í›„ RRF ê²°ê³¼: {len(top_docs)}")

        # [Step 7] Post-Filtering: Python ë ˆë²¨ì˜ ê°•í™”ëœ ì§€ì—­ í•„í„°ë§
        final_docs = self.region_filter.post_filter(top_docs, detected_region_code)
        logger.debug(f"Post-filter í›„ ìµœì¢… ë¬¸ì„œ ìˆ˜: {len(final_docs)}")
        
        # íŠ¹ì • ì§€ì—­ ê²€ìƒ‰ ì‹œ ë‹¤ë¥¸ ì§€ì—­ì˜ ì •ì±…ì´ ì„ì—¬ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê°•í™”ëœ ê²€ì¦ ë¡œì§ (ì›ë³¸ ìœ ì§€)
        if detected_region_code and final_docs:
            region_validated_docs = []
            for doc in final_docs:
                if doc.metadata.get('region_scope') == 'national':
                    region_validated_docs.append(doc)
                    continue
                
                sido_json = doc.metadata.get('regions_code.sido', '[]')
                sigungu_json = doc.metadata.get('regions_code.sigungu', '[]')
                
                try:
                    doc_sido = json.loads(sido_json) if isinstance(sido_json, str) else sido_json
                    doc_sigungu = json.loads(sigungu_json) if isinstance(sigungu_json, str) else sigungu_json
                except:
                    doc_sido = []
                    doc_sigungu = []
                
                if not isinstance(doc_sido, list): doc_sido = [doc_sido] if doc_sido else []
                if not isinstance(doc_sigungu, list): doc_sigungu = [doc_sigungu] if doc_sigungu else []
                
                if detected_region_code in doc_sido or detected_region_code in doc_sigungu:
                    region_validated_docs.append(doc)
                else:
                    logger.debug(f"í•„í„° ì œì™¸ë¨ - ì •ì±…: {doc.metadata.get('ì •ì±…ëª…')}, ì‹œë„: {doc_sido}, ì‹œêµ°êµ¬: {doc_sigungu}")
            
            final_docs = region_validated_docs

        # [Step 8] Answer Generation
        context = self.memory.get_context()
        
        docs_text_list = []
        for d in final_docs[:5]:
            title = d.metadata.get('ì •ì±…ëª…', 'ì •ë³´ ì—†ìŒ')
            # ë©”íƒ€ë°ì´í„°ì—ì„œ URL ì¶”ì¶œ
            url = d.metadata.get('ì°¸ê³ URL1') or d.metadata.get('ì‹ ì²­URL') or 'ì •ë³´ ì—†ìŒ'
            content = d.page_content
            
            doc_item = f"ì •ì±…ëª…: {title}\nì°¸ê³  URL: {url}\në‚´ìš©: {content}"
            docs_text_list.append(doc_item)
            
        docs_text = "\n\n===\n\n".join(docs_text_list)
        
        response_chain = self.answer_prompt | self.llm | StrOutputParser()
        answer = response_chain.invoke({
            "context": context,
            "documents": docs_text,
            "query": user_query
        })

        self.memory.add_message("assistant", answer)

        return {
            "answer": answer,
            "detected_region": active_region_info,
            "source_documents": final_docs[:3]
        }



# í…ŒìŠ¤íŠ¸
from dotenv import load_dotenv
load_dotenv()


def initialize_test_system():
    """í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    logger.info("--- [ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘] ---")
    
    # 1. í™˜ê²½ ì„¤ì •
    api_key = os.getenv("OPENAI_API_KEY")
    vectordb_path = "./data/vectordb2"  # ì‹¤ì œ ì €ì¥ëœ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”
    regions_code_path = "./data/regions_code.json" # íŒŒì¼ ê²½ë¡œ

    # 2. LLM ë° ì„ë² ë”© ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    # # 2. LLM ë° ì„ë² ë”© ì„¤ì •
    # llm = ChatOpenAI(model="gpt-5.1", temperature=0)
    # embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    # 3. VectorDB ë¡œë“œ
    vectorstore = Chroma(
        persist_directory=vectordb_path,
        embedding_function=embeddings,
        collection_name="youth_policies"
    )

    # 4. regions_code.json ë°ì´í„° ë¡œë“œ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)
    with open(regions_code_path, 'r', encoding='utf-8') as f:
        regions_data = json.load(f)

    # 5. BM25ìš© ì „ì²´ ë¬¸ì„œ ì¶”ì¶œ (VectorDBì—ì„œ ê¸ì–´ì˜´)
    logger.info("ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    all_docs_data = vectorstore.get()
    
    if not all_docs_data or not all_docs_data.get('documents'):
        logger.error("VectorDBì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")
        logger.debug(f"VectorDB ê²½ë¡œ: {vectordb_path}")
        logger.debug(f"Metadata: {all_docs_data}")
        raise ValueError("VectorDBì—ì„œ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    logger.info(f"ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(all_docs_data['documents'])}")
    
    from langchain_core.documents import Document
    documents = [
        Document(page_content=text, metadata=meta) 
        for text, meta in zip(all_docs_data['documents'], all_docs_data['metadatas'])
        if text
    ]

    logger.info(f"ì²˜ë¦¬ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")

    pipeline = AdvancedRAGPipeline(
        vectorstore=vectorstore,
        regions_data=regions_data,
        llm=llm,
        documents=documents
    )
    
    return pipeline


def main():
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    pipeline = initialize_test_system()

    print("ì²­ë…„ì´ìŒ ì„ ë°°ë´‡ CLI í…ŒìŠ¤íŠ¸ ëª¨ë“œ")

    while True:
        user_input = input("ì§ˆë¬¸: ").strip()
        
        if user_input in ["ì¢…ë£Œ", "exit", "quit"]:
            print("ì„ ë°°ë´‡: ë‹¤ìŒì— ë˜ ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´! ì•ˆë…•~ğŸ‘‹")
            break
        
        if not user_input:
            continue

        try:
            # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            result = pipeline.query(user_input)
            
            # ê²°ê³¼ ì¶œë ¥ (ì‚¬ìš©ì ì‘ë‹µë§Œ ì¶œë ¥)
            print(f"\n{result['answer']}\n")
            
        except Exception as e:
            logger.exception(e)

if __name__ == "__main__":
    main()
