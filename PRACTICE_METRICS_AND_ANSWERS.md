# π¦† Pseudo Practice: AI Evaluation Metrics & Answer Key

μ΄ λ¬Έμ„λ” **Pseudo Practice (Coduck Wars)** λ¨λ“μ AI ν‰κ°€ λ©”μ»¤λ‹μ¦κ³Ό κ° μ¤ν…μ΄μ§€λ³„ λ΅μ»¬ μ •λ‹µ κ°€μ΄λ“λ¥Ό λ‹΄κ³  μμµλ‹λ‹¤.

---

## β–οΈ 1. AI κΈ°λ° 5μ°¨μ› λ©”νΈλ¦­ ν‰κ°€ μ‹μ¤ν…

λ³Έ ν”λ«νΌμ€ λ‹¨μν μ½”λ“κ°€ λμ•„κ°€λ”μ§€λ¥Ό λ„μ–΄, μ‹λ‹μ–΄ μ—”μ§€λ‹μ–΄ κ΄€μ μ—μ„ μ‚¬μ©μμ **'μ‚¬κ³ μ κΉμ΄'**λ¥Ό μΈ΅μ •ν•©λ‹λ‹¤.

| ν‰κ°€ ν•­λ© | κ³µμ‹ μ •μ (In-Game) | μƒμ„Έ ν‰κ°€ κΈ°μ¤€ | λ°°μ  |
| :--- | :--- | :--- | :--- |
| **μ •ν•©μ„± (Consistency)** | **μ”κµ¬μ‚¬ν•­ μ¶©μ‹¤λ„** | λ―Έμ… λ©ν‘(Quest Title) λ° μ μ•½ μ‚¬ν•­κ³Ό μ‚¬μ©μ μ„¤κ³„μ μΌμΉ μ—¬λ¶€ | 0-100 |
| **μ¶”μƒν™” (Abstraction)** | **λ΅μ§ κ°„κ²°μ„±** | μμ‚¬μ½”λ“μ—μ„ λ¶ν•„μ”ν• μ„Έλ¶€ μ‚¬ν•­μ„ μ κ±°ν•κ³  ν•µμ‹¬ λ΅μ§μ„ κ°„κ²°ν•κ² ν‘ν„ν–λ”κ°€ | 0-100 |
| **μμ™Έμ²λ¦¬ (Exception)** | **μ„ν— λ€μ‘λ ¥** | λ°μ΄ν„° λ„μ, λ“λ¦¬ν”„νΈ, λ―Έν™•μΈ λ°μ΄ν„° λ“± μμ™Έ μƒν™©μ— λ€ν• λ°©μ–΄ λ΅μ§ ν¬ν•¨ μ—¬λ¶€ | 0-100 |
| **κµ¬ν„λ ¥ (Implementation)** | **μ½”λ“ μ •ν™•λ„** | μμ‚¬μ½”λ“λ¥Ό μ‹¤μ  νμ΄μ¬ ν‘μ¤€ λ¬Έλ²• λ° λΌμ΄λΈλ¬λ¦¬(Scikit-Learn λ“±)λ΅ λ³€ν™ν•λ” λ¥λ ¥ | 0-100 |
| **μ„¤κ³„λ ¥ (Design)** | **κµ¬μ΅° ν™•μ¥μ„±** | μ „μ²΄ λ°μ΄ν„° νμ΄ν”„λΌμΈμ λ‹¨κ³„λ³„ μ—°κ²°μ„± λ° μ•„ν‚¤ν…μ²μ  μ™„μ„±λ„ | 0-100 |

---

## π“ 2. μµμΆ… μ μ μ‚°μ¶ κ³µμ‹ (Calculation Logic)

λ¦¬ν¬νΈμ μµμΆ… μ μλ” **'μ‹¤λ¬΄ νΌν¬λ¨Όμ¤'**μ™€ **'κ±΄μ¶•μ  μ‚¬κ³ λ ¥'**μ„ 4:6 λΉ„μ¨λ΅ μ΅°ν•©ν•μ—¬ μ‚°μ¶ν•©λ‹λ‹¤. λ‹¨μν ν•λ‹¨ μ§€ν‘μ ν‰κ· κ°’μ΄ μ•„λ‹μ— μ μν•μ‹­μ‹μ¤.

> **μµμΆ… μ μ = (κ²μ„ νΌν¬λ¨Όμ¤ Score Γ— 0.4) + (AI μ•„ν‚¤ν…νΈ λ…Όλ¦¬ μ μ Γ— 0.6)**

*   **κ²μ„ νΌν¬λ¨Όμ¤ (40%):** λ―Έμ… μ§„ν–‰ μ¤‘μ μ •λ‹µλ¥ , λ‚¨μ€ μ‹μ¤ν… HP, μ†μ” μ‹κ°„ λ“±μ„ μΆ…ν•©ν•©λ‹λ‹¤.
*   **AI μ•„ν‚¤ν…νΈ ν‰κ°€ (60%):** μ‚¬μ©μκ°€ μ‘μ„±ν• μμ—°μ–΄ λ΅μ§κ³Ό Python μ½”λ“ κ°„μ μ •ν•©μ„±, μ„¤κ³„μ κΉμ΄λ¥Ό λ¶„μ„ν• μ μμ…λ‹λ‹¤. 
    *   *μ°Έκ³ : 5λ€ κ°€λ΅ μ§€ν‘(μ •ν•©μ„±~μ„¤κ³„λ ¥)λ” AI μ•„ν‚¤ν…νΈ ν‰κ°€(60%) λ‚΄μ μ„Έλ¶€ ν•­λ©μ…λ‹λ‹¤.*

---

---

## π† 3. μ¤ν…μ΄μ§€λ³„ μ •λ‹µ κ°€μ΄λ“ (Answer Key)

### μ¤ν…μ΄μ§€ 1: μ‚¬κ³  νλ΅ λ³µκµ¬ (Data Leakage)
*   **ν•µμ‹¬ λ©ν‘**: μ „μ²λ¦¬ μ‹ Train λ°μ΄ν„° μ •λ³΄κ°€ Testλ΅ μ μ¶λλ” ν„μƒ λ°©μ§€.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ „μ²΄ νλ¦„ νμ•…ν•κΈ° / μλ»λ ν•™μµ κΈ°μ¤€(Fit)
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `train`, `test`, `fit`, `transform`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    scaler = StandardScaler()
    scaler.fit(train_df)
    train_scaled = scaler.transform(train_df)
    test_scaled = scaler.transform(test_df)
    ```

### μ¤ν…μ΄μ§€ 2: λ°μ΄ν„° λ„μ κ°€λ””μ–Έ (Target Leakage)
*   **ν•µμ‹¬ λ©ν‘**: μ‹κ³„μ—΄ λ°μ΄ν„° μ²λ¦¬ μ‹ λ―Έλ λ°μ΄ν„° μ‚¬μ© κΈμ§€.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ‹κ°„ μμ„ λ¶„λ¦¬(Time-based Split) / μ¤μ§ ν•™μµμ© λ°μ΄ν„°λ΅λ§ fit
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `μ‹κ°„`, `λ¶„λ¦¬`, `fit`, `train`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    df = df.sort_values('date')
    train_df = df[df['date'] < threshold_date]
    test_df = df[df['date'] >= threshold_date]
    ```

### μ¤ν…μ΄μ§€ 3: ν•™μµ-μ„λΉ™ λ¶μΌμΉ (Skew)
*   **ν•µμ‹¬ λ©ν‘**: λ°μ΄ν„° μμ„μ— μν• νΈν–¥ λ°©μ§€λ¥Ό μ„ν• μ…”ν”λ§.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ „μ²λ¦¬ λ΅μ§ λ¶μΌμΉ / μ‹κ³„μ—΄ κΈμµ λ°μ΄ν„°
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `μ…”ν”`, `μμ„`, `νΈν–¥`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    indices = list(range(len(data)))
    random.shuffle(indices)
    shuffled_data = [data[i] for i in indices]
    ```

### μ¤ν…μ΄μ§€ 4: μ„κ³„κ°’ νλ„ (Deployment Policy)
*   **ν•µμ‹¬ λ©ν‘**: λΉ„μ¦λ‹μ¤ λ¦¬μ¤ν¬ κΈ°λ° μμΈ΅ μλ½ μ—¬λ¶€ κ²°μ •.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ¬ν„μ¨ (Recall) / μ‹¤μ  ν™μλ¥Ό μ •μƒμΌλ΅ μ¤ν (FN)
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `μ„κ³„κ°’`, `ν•„ν„°`, `μ‹ λΆ°λ„`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    if p['score'] >= threshold:
        filtered_results.append(p)
    ```

### μ¤ν…μ΄μ§€ 5: κ°λ… λ“λ¦¬ν”„νΈ κ°μ§€ (Monitor)
*   **ν•µμ‹¬ λ©ν‘**: μ‹κ°„μ΄ μ§€λ‚¨μ— λ”°λ¥Έ μ„±λ¥ μ €ν• μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: κ°λ… λ“λ¦¬ν”„νΈ (Concept Drift) / λ¨λΈ μ¬ν•™μµ (Retraining)
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `λ³€ν™”`, `μ¤μ°¨`, `λ¨λ‹ν„°λ§`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    error = (r - p)**2
    errors.append(error)
    return sum(errors) / len(real)
    ```

### μ¤ν…μ΄μ§€ 6: μ°¨μ›μ μ €μ£Όμ™€ μΈμ½”λ”© (Preprocessing)
*   **ν•µμ‹¬ λ©ν‘**: κ³ μ°¨μ› λ²”μ£Όν• λ³€μμ ν¨μ¨μ  μ²λ¦¬ λ° μμ™Έ μ²λ¦¬.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ°¨μ›μ μ €μ£Ό / μ„λ² λ”©(Embedding)
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `μ°¨μ›`, `μμ™Έ`, `μΈμ½”λ”©`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    result = mapping.get(category, mapping['Unknown'])
    ```

### μ¤ν…μ΄μ§€ 7: λ¶ν™•μ‹¤μ„± κ΄€λ¦¬ (Uncertainty)
*   **ν•µμ‹¬ λ©ν‘**: λ¨λΈμ΄ μ‹ λΆ°ν•  μ μ—†λ” κ²½μ° κ²°μ •μ„ μ λ³΄ν•λ” μ „λµ.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ‹ λΆ°λ„ λ¶•κ΄΄ / ν™•μ‹ λ„(Margin) μΈ΅μ •
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `ν™•λ¥ `, `λΉ„κµ`, `μ‹ λΆ°`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    max_val = max(probs)
    return probs.index(max_val)
    ```

### μ¤ν…μ΄μ§€ 8: μμ› μµμ ν™” (Early Stopping)
*   **ν•µμ‹¬ λ©ν‘**: κ³Όμ ν•© λ°©μ§€ λ° ν•™μµ μμ› λ‚­λΉ„ μ°¨λ‹¨.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: μ–Όλ¦¬ μ¤ν† ν•‘ (Early Stopping) / λ΅μ»¬ λ―Έλ‹λ§ νƒμ¶ κΈ°ν μ μ•
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `μ¤‘λ‹¨`, `κ°μ„ `, `λΉ„μ©`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    no_improve_count += 1
    if no_improve_count >= patience:
        return True
    ```

### μ¤ν…μ΄μ§€ 9: κ°•ν™”ν•™μµ (Dynamic Optimization)
*   **ν•µμ‹¬ λ©ν‘**: Explorationκ³Ό Exploitationμ κ· ν• μλ¦½.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: κ°•ν™” ν•™μµ (Reinforcement Learning) / λ” ν° λ³΄μƒ(Global Optimum) νƒμƒ‰
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `νƒν—`, `ν™μ©`, `κ· ν•`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    if random.random() < epsilon:
        return random.randint(0, len(q_values)-1)
    return q_values.index(max(q_values))
    ```

### μ¤ν…μ΄μ§€ 10: κ°μΈμ •λ³΄ μ •ν™” (PII Tokenizer)
*   **ν•µμ‹¬ λ©ν‘**: λ³΄μ•μ΄ ν™•λ³΄λ λ°μ΄ν„° μ •μ  λ° μ •κ·ν™”.
*   **Step 1 μΈν„°λ·° μ •λ‹µ**: κ°μΈμ •λ³΄ λ§μ¤ν‚Ή / μλ―Έμ  μΌκ΄€μ„± ν™•λ³΄
*   **Step 2 μμ‚¬μ½”λ“ ν•„μ ν‚¤μ›λ“**: `μ •κ·ν™”`, `μ κ±°`, `ν† ν°`
*   **Step 3 νμ΄μ¬ κµ¬ν„ μ •λ‹µ**:
    ```python
    clean_text = re.sub(r'[^\w\s]', '', text)
    tokens = clean_text.lower().split()
    return [t for t in tokens if t.strip()]
    ```

---

*λ³Έ κ°€μ΄λ“λ” μ•„ν‚¤ν…νΈ λ“±κΈ‰ λ‹¬μ„±μ„ μ„ν• μµμ† κΈ°μ¤€μ…λ‹λ‹¤. AI ν‰κ°€λ” λ¬Έμ¥μ λ…Όλ¦¬μ  μ—°κ²°μ„±κΉμ§€ λ¶„μ„ν•λ―€λ΅, κ²°κ³Ό λ¦¬ν¬νΈμ ν”Όλ“λ°±μ„ μ£Όμ κΉκ² ν™•μΈν•μ‹­μ‹μ¤.*
