# 아키텍처 평가 시스템 고도화 방안: 에이전트 기반 딥다이브 전환

> 기존 문서 3개(`interview_data_analysis.md`, `implementation_plan.md`, `interview_data_full_utilization.md`)와 Claude 자문 논의를 통합한 최종 고도화 방안

---

## 1. 현재 시스템의 한계 (As-Is)

### 현재 흐름
```
사용자 아키텍처 입력
  → 6대 기둥 기반 질문 3개 한 번에 생성
  → 사용자가 순차 답변
  → Master Agent가 답변 평가
  → 결과 표시
```

### 핵심 문제점

**질문이 1회성이고 적응하지 않는다.**
현재 시스템은 사용자의 아키텍처만 보고 질문 3개를 한 번에 생성한다. 사용자의 답변 품질에 따라 더 깊이 파거나 다음 주제로 넘어가는 판단이 없다. 실제 면접에서는 인터뷰어가 답변을 듣고 "이 사람이 이걸 이해하고 있는가?"를 판단한 뒤 다음 행동을 결정한다.

**질문 패턴이 추상적이다.**
6대 기둥 txt 파일의 원칙(principles)만으로 질문을 생성하기 때문에, "시스템의 가용성을 어떻게 보장하나요?" 수준의 교과서적 질문이 나온다. 실제 FAANG 면접관은 "4th of July 저녁에 1000만 이벤트가 동시 진행될 때, 화요일 오후 알래스카와는 극적으로 다른 트래픽인데, 배치 잡으로 처리 가능합니까?"라고 묻는다.

**점수 산정의 근거가 약하다.**
1회 답변만으로 해당 지표에 대한 사용자의 이해도를 판단하기 때문에, 한 번의 답변이 모호하면 "이해는 하지만 표현을 못 한 건지" vs "진짜 모르는 건지" 구분이 불가능하다.

---

## 2. 고도화 방향: 에이전트 기반 적응형 딥다이브

### 핵심 변경
1회성 질문 3개 → **갈래별 적응형 딥다이브**로 전환한다. 하나의 갈래(주제)에 대해 질문하고, 답변의 충분성을 판정한 뒤, 충분하면 다음 갈래로 이동하고 불충분하면 같은 갈래에서 더 깊이 파고드는 구조.

### To-Be 흐름
```
[사용자 아키텍처 입력]
        ↓
[분석 에이전트] → 취약 갈래 2~4개 식별 + 우선순위 결정
        ↓
[질문 에이전트] → 갈래 1의 첫 질문 생성
        ↓
[사용자 답변]
        ↓
[판정 에이전트] → 2가지 중 하나 판정:
    ├─ "충분" → 다음 갈래로 이동
    └─ "불충분" → 딥다이브 질문 (같은 갈래, 다른 각도에서 재질문)
           └─ 최대 2회 추가, 이후에도 불충분이면 기록 후 다음 갈래로
        ↓
[모든 갈래 완료]
        ↓
[평가 에이전트] → 전체 Q&A 기반 종합 평가
```

---

## 3. 에이전트 구성 상세

### 3.1 분석 에이전트 (Analyzer Agent)

**역할:** 사용자의 아키텍처와 설명을 분석하여 취약한 갈래(주제)를 2~4개 식별하고, 우선순위를 결정한다.

**갈래 수를 3개로 고정하지 않는 이유:**
인터뷰 스크립트 분석 결과, 문제마다 중요한 갈래 수가 다르다.

| 문제 | 실제 핵심 갈래 수 | 주요 갈래 |
|------|:----------------:|----------|
| Banking Ledger | 4 | 인증, DB 설계, reconciliation, data tiering |
| Gaming Leaderboard | 3 | 캐싱, 정렬, 월간 리셋 |
| Live Comment | 2 (사실상 1) | push vs pull이 전체의 70% |
| Calendar | 3 | DB 설계, 알림 시스템, 시간 범위 쿼리 |

따라서 고정 3개보다는 아키텍처 분석 후 **2~4개 범위에서 동적으로 결정**하는 것이 적합하다.

**입력:** 사용자 아키텍처 + 설명 + 문제 시나리오
**출력:** 취약 갈래 목록 (2~4개) + 각 갈래의 우선순위 + 갈래별 첫 질문 방향성

### 3.2 질문 에이전트 (Questioner Agent)

**역할:** 분석 에이전트가 식별한 갈래에 대해, 사용자의 아키텍처 맥락에 맞는 구체적 질문을 생성한다.

**질문 품질 강화 — 인터뷰 스크립트 데이터 활용:**
현재 보유한 34개 인터뷰 트랜스크립트에서 추출한 실제 면접관 질문 패턴을 few-shot 예시로 프롬프트에 주입한다.

| 질문 유형 | 설명 | 실제 예시 |
|-----------|------|----------|
| What-if 시나리오 | 극단적 상황을 제시하여 설계의 한계를 검증 | "모든 worker가 동시에 죽으면 큐에 메시지가 계속 쌓이는데, 어떻게 감지하나요?" |
| 트레이드오프 강제 | 설계 결정의 근거를 요구 | "Push vs Pull 중 왜 Push를 선택? Pull의 장단점은?" |
| 꼬리질문 심화 | 답변의 구멍을 정확히 지적 | "배치 잡의 주기가 5분이면, 트래픽이 극적으로 다른 상황에서 같은 5분으로 처리 가능?" |

**입력:** 현재 갈래 + 사용자 아키텍처 + (있다면) 이전 Q&A 기록
**출력:** 질문 1개

### 3.3 판정 에이전트 (Judge Agent)

**역할:** 사용자의 답변이 해당 갈래에서 "충분한가"를 판정한다. **질문 에이전트와 분리하는 이유는 자기 질문에 대한 관대/엄격 편향을 방지하기 위함이다.**

**판정 기준 (인터뷰 스크립트에서 추출):**

실제 면접관이 "넘어가는" 순간과 "더 파고드는" 순간의 패턴을 분석한 결과, 3가지 기준이 관찰됨:

| 기준 | 판정 | 스크립트 근거 |
|------|------|-------------|
| 핵심 키워드 + 이유를 함께 제시 | **충분** | Calendar: "postgres because it handles concurrent requests better" → 인터뷰어: "Full points. Let's keep going." |
| 키워드만 있고 이유 없음, 또는 모호한 답변 | **불충분** | Facebook Events: "캐시를 쓰겠습니다" → 인터뷰어: "어디에? 왜?" |
| 같은 방향의 답변을 2번 반복 | **불충분 (기록 후 다음 갈래)** | Facebook Events: 서버 내부 캐시를 3번 반복 → 인터뷰어가 포기하고 주제 전환 |

**판정 에이전트 프롬프트에 포함할 few-shot:**
```
[충분한 답변 예시]
Q: "왜 PostgreSQL을 선택했나요?"
A: "트랜잭션 데이터이므로 ACID가 필요하고, PostgreSQL이 동시 요청 처리에 강점이 있어서 선택했습니다."
→ 판정: 충분. 키워드(PostgreSQL, ACID) + 이유(동시 요청 처리) 모두 포함.

[불충분한 답변 예시]
Q: "메시지 큐가 실패하면 어떻게 하나요?"
A: "재시도를 하겠습니다."
→ 판정: 불충분. 재시도 전략(횟수, 간격, DLQ)이 없고, 감지 방법도 없음.
```

**입력:** 현재 질문 + 사용자 답변 + 해당 갈래 정보
**출력:** "충분" 또는 "불충분" + 판정 근거

### 3.4 평가 에이전트 (Evaluator Agent)

**역할:** 모든 갈래의 Q&A가 완료된 후, 전체 대화 기록을 기반으로 종합 평가를 수행한다.

**점수 산정 로직:**

딥다이브 깊이가 곧 점수 근거가 된다. 힌트 없이, 사용자가 몇 번째 질문에서 충분한 답에 도달했는가로 평가한다.

| 갈래 내 도달 시점 | 점수 반영 |
|:----------------:|----------|
| 첫 질문에서 충분 | 해당 갈래 만점 |
| 딥다이브 1회 후 충분 | 해당 갈래 중간 점수 |
| 딥다이브 2회 후 충분 | 해당 갈래 하점 |
| 2회 후에도 불충분 | 해당 갈래 최하점 |

**평가에 포함되는 요소 (인터뷰 스크립트 기반 루브릭):**

| 평가 축 | 비중 | 설명 |
|---------|:----:|------|
| 트레이드오프 논의 | 25% | 설계 결정마다 대안 제시 + 선택 근거 |
| 핵심 문제(Core Puzzle) 파악 | 20% | 해당 문제의 가장 중요한 설계 포인트를 잡았는가 |
| 요구사항 수집 | 15% | FR/NFR을 사용자 관점으로 도출했는가 |
| 데이터 모델링 | 15% | 스키마, 인덱싱, 파티셔닝 전략 |
| 장애 대응 | 15% | 실패 시나리오를 선제적으로 언급했는가 |
| 커뮤니케이션 | 10% | 구조적 설명, 시간 배분 |

**피드백 출력 구조:**
```
{
  "overall_score": 75,
  "estimated_level": "L5",
  "per_branch_results": [
    {
      "branch": "reliability",
      "depth_reached": 2,        // 딥다이브 2회만에 충분
      "score": 60,
      "feedback": "재시도 전략은 언급했으나 DLQ, 모니터링이 없음",
      "reference_answer": "모범답안..."
    }
  ],
  "strengths": ["..."],
  "improvements": ["..."],
  "learning_tips": [
    "이 질문에서 client-side caching을 고려하지 못했습니다. 비행기 모드에서도 캘린더 알림이 울리는 이유를 생각해보세요."
  ]
}
```

---

## 4. 핵심 설계 결정과 근거

### 4.1 힌트를 제거한 이유

초기 논의에서 "불충분 판정 시 힌트를 제공하고 재질문"하는 방안을 검토했다. 그러나 이를 제거한 근거는 다음과 같다:

**점수 산정이 흔들린다.** 같은 "client-side caching" 답변이어도 혼자 도달한 사람과 힌트 2번 받고 도달한 사람이 같은 점수면 안 된다. 힌트 횟수에 따른 감점 비율을 정하는 것 자체가 새로운 설계 문제가 된다.

**힌트 반응 품질까지 평가하면 복잡도가 폭발한다.** 스크립트 분석 결과, Banking Ledger에서 인터뷰어가 PUT vs POST 힌트를 줬는데 지원자가 바로 이해하고 확장한 건 가점이었고, Facebook Events에서 힌트 3번 줬는데도 못 잡은 건 감점이었다. "힌트를 받았을 때의 반응 품질"까지 평가하면 판정 에이전트의 복잡도가 과도하게 증가한다.

**대안:** 힌트는 최종 평가의 `learning_tips` 필드에서 제공한다.
"이 질문에서 X를 고려하지 못했습니다. Y를 생각해보세요."
→ 점수와 학습을 분리하여, 점수는 순수하게 답변 품질로만 산정하고 학습 피드백은 별도로 제공한다.

### 4.2 판정 에이전트를 별도로 분리한 이유

질문하는 에이전트와 "이 답변이 충분한가"를 판단하는 에이전트가 같으면, 자기가 만든 질문에 대해 관대해지거나 엄격해지는 편향이 생긴다. 인터뷰 스크립트에서도 면접관은 한 사람이지만 "질문하는 모드"와 "판단하는 모드"가 분명히 구분된다. 에이전트 구조에서는 이를 물리적으로 분리하는 것이 가능하므로 분리한다.

### 4.3 턴 제한을 설정한 이유

실제 면접은 45분 제한이 있어서 자연스럽게 끊긴다. LLM 에이전트는 제한이 없으면 무한히 파고들 수 있다.

**스크립트 기반 턴 통계:**

| 스크립트 | 갈래 수 | 갈래당 평균 턴 | 총 Q&A 턴 |
|----------|:------:|:------------:|:--------:|
| Banking Ledger | 4 | 3 | ~12 |
| Live Comment | 2 | 4 | ~8 |
| Photo Sharing | 3 | 3 | ~9 |
| Calendar | 3 | 3~4 | ~10 |
| Video Processing | 3 | 2~3 | ~8 |

따라서 설정: **한 갈래당 최대 3턴 (첫 질문 + 딥다이브 최대 2회), 전체 최대 9~12턴.**

---

## 5. 인터뷰 데이터 활용 방안

### 5.1 질문 에이전트의 프롬프트 레퍼런스

34개 인터뷰 스크립트에서 추출한 면접관 질문을 **지표별로 분류**하여 few-shot 예시로 활용한다. 이 데이터는 `interview_analysis.md`의 6번(6가지 평가 지표 전환)에서 이미 정리되어 있다.

**역할:** "이런 수준과 스타일로 질문을 생성하라"는 레퍼런스
**위치:** 질문 에이전트 프롬프트 내 few-shot 섹션

### 5.2 판정 에이전트의 충분성 기준

스크립트에서 인터뷰어가 "넘어간 순간"과 "더 파고든 순간"을 추출하여, 충분/불충분 판정의 few-shot으로 활용한다.

**역할:** "이 수준이면 충분하고, 이 수준이면 불충분하다"는 판정 기준
**위치:** 판정 에이전트 프롬프트 내 예시 섹션

### 5.3 평가 에이전트의 루브릭

스크립트의 피드백 섹션에서 추출한 레벨별 평가 기준(L4/L5/L6)과 평가 축을 루브릭으로 활용한다.

**역할:** "FAANG 면접관이 실제로 보는 관점으로 평가하라"는 채점 기준
**위치:** 평가 에이전트 프롬프트 내 루브릭 섹션

### 5.4 평가 신뢰성 검증의 골든 데이터셋

6번에서 추출한 지표별 질문 예시가 "좋은 질문의 레퍼런스"이자 동시에 **품질 검증 기준**이 된다.

**평가 신뢰성의 정의 (Claude 자문 기반):**
"같은 질문이 나오는가"가 아니라, **"어떤 아키텍처가 들어오든, 취약한 부분을 일관되게 잘 짚어내는가"**로 정의한다. 사용자마다 아키텍처가 다르므로 출력의 동일성이 아니라 출력의 품질 일관성을 본다.

**검증 방법:**
1. 다양한 아키텍처 샘플(10~20개)을 입력
2. 각 샘플에 대해 생성된 질문이 실제 약점을 짚고 있는지 수동 검토
3. 이 결과를 골든 데이터셋으로 구축
4. 이후 LLM-as-a-Judge로 자동 검증을 수행하되, 골든 데이터셋에 calibrate

---

## 6. 기존 implementation_plan.md와의 관계

기존 7단계 Phase 계획과 본 고도화 방안의 관계:

| 기존 Phase | 본 방안에서의 위치 | 변경 사항 |
|-----------|-----------------|----------|
| Phase 1: 데이터 전처리 | **그대로 유지** | 34개 파일로 확대 |
| Phase 2: 질문 품질 강화 | **질문 에이전트로 흡수** | few-shot → 에이전트 프롬프트 내장 |
| Phase 3: 평가 루브릭 강화 | **평가 에이전트로 흡수** | 루브릭 → 에이전트 프롬프트 내장 |
| Phase 4: 실수 감지 + 힌트 | **힌트 제거, 실수 감지만 유지** | 판정 에이전트가 실수 감지 역할 겸임 |
| Phase 5: Core Puzzle | **분석 에이전트에 통합** | 갈래 식별 시 Core Puzzle 우선 |
| Phase 6: 면접 전략 팁 | **평가 에이전트의 learning_tips로 이동** | 실시간 제공 → 사후 피드백으로 변경 |
| Phase 7: 꼬리질문 체인 | **에이전트 구조의 핵심이 됨** | 1회성 꼬리질문 → 적응형 딥다이브 |

---

## 7. 구현 우선순위

### Step 1: 데이터 전처리 (기반 작업)
34개 인터뷰 스크립트에서 다음을 추출하여 JSON으로 구조화:
- 면접관 질문 패턴 (질문 에이전트용 few-shot)
- 충분/불충분 답변 쌍 (판정 에이전트용 few-shot)
- 레벨별 평가 루브릭 (평가 에이전트용)
- 주제별 Core Puzzle (분석 에이전트용)

### Step 2: 판정 에이전트 먼저 구현
가장 핵심적이면서도 독립적으로 테스트 가능한 에이전트. 기존 1회성 질문에 판정 에이전트만 추가해도, "답변이 충분한지 판단 → 충분하면 다음으로"라는 최소 적응형 흐름이 만들어진다.

### Step 3: 분석 + 질문 에이전트 구현
판정 에이전트가 안정되면, 갈래 식별(분석)과 갈래별 질문 생성(질문)을 추가하여 전체 파이프라인을 완성한다.

### Step 4: 평가 에이전트 고도화
전체 Q&A 기록을 기반으로 한 종합 평가. 딥다이브 깊이 기반 점수 산정 + 루브릭 기반 레벨 판정.

### Step 5: 골든 데이터셋 구축 및 검증
10~20개 테스트 케이스로 수동 검증 → LLM-as-a-Judge calibration.

---

## 8. 예상 사용자 경험 비교

### As-Is (현재)
```
시스템: "신뢰성 관점에서 이 시스템의 가용성을 어떻게 보장하나요?"
사용자: "로드 밸런서를 쓰겠습니다."
시스템: 다음 질문으로 이동 (답변 부족 여부 판단 없음)
```

### To-Be (고도화 후)
```
시스템: "이 비디오 처리 워커가 절반이 동시에 죽으면, 큐에 메시지가 쌓이는 걸 어떻게 감지하나요?"
사용자: "모니터링 시스템을 사용합니다."
시스템: [판정: 불충분 - 구체적 감지 방법 없음]
시스템: "어떤 메트릭을 모니터링하나요? 큐 길이? 처리 지연? 감지 후 자동 복구는 어떻게?"
사용자: "큐 길이가 임계값을 넘으면 Kubernetes가 워커를 자동 스케일링합니다."
시스템: [판정: 충분 - 메트릭(큐 길이) + 임계값 + 자동 복구(K8s) 포함]
시스템: 다음 갈래로 이동
```

---

## 9. 리스크 및 대응

| 리스크 | 영향 | 대응 |
|--------|------|------|
| LLM 호출 횟수 증가 (갈래당 2~3회 × 4갈래) | 비용, 지연 | 판정 에이전트를 경량 모델(gpt-4o-mini)로, 질문/평가 에이전트를 상위 모델로 분리 |
| 판정 에이전트의 판정 일관성 부족 | 사용자마다 기준이 달라 보이는 문제 | few-shot 예시를 충분히 확보 + 골든 데이터셋 calibration |
| 사용자가 답변을 매우 길게 작성하는 경우 | 판정 에이전트의 토큰 소비 | 답변 길이 제한(500자) 또는 요약 후 판정 |
| 무한 루프 (판정이 계속 불충분) | UX 파괴 | 갈래당 최대 3턴 하드캡 |
