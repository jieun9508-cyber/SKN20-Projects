/**
 * LLM-Based Interview Data Classifier
 *
 * [ìƒì„±ì¼: 2026-02-09]
 * [ëª©ì : feedback.mdì˜ "NLP ëŒ€ì‹  Few-shot Learning" í”¼ë“œë°± ë°˜ì˜]
 *
 * í‚¤ì›Œë“œ ë§¤ì¹­ ëŒ€ì‹  LLM Few-shot Learningìœ¼ë¡œ ë©´ì ‘ ë°ì´í„° ë¶„ë¥˜
 * - ë§¥ë½ì„ ì´í•´í•˜ë©° ë¶„ë¥˜
 * - False Positive ê°ì†Œ
 * - ê°•ì /ì•½ì  êµ¬ë¶„
 */

const getApiKey = () => import.meta.env.VITE_OPENAI_API_KEY;

/**
 * LLMì„ ì‚¬ìš©í•˜ì—¬ ë©´ì ‘ í”¼ë“œë°± ë¶„ë¥˜
 *
 * @param {string} summary - ë©´ì ‘ í”¼ë“œë°± ìš”ì•½
 * @param {string} title - ë©´ì ‘ ì œëª© (ì»¨í…ìŠ¤íŠ¸)
 * @returns {Promise<Object>} ë¶„ë¥˜ ê²°ê³¼
 */
export async function classifyInterviewFeedback(summary, title = '') {
  const prompt = `ë‹¹ì‹ ì€ ì‹œìŠ¤í…œ ë””ìì¸ ë©´ì ‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë©´ì ‘ í”¼ë“œë°±ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

## ë©´ì ‘ ì œëª©
${title}

## í”¼ë“œë°± ë‚´ìš©
${summary}

## ë¶„ë¥˜ ê¸°ì¤€

### 6ëŒ€ ê¸°ë‘¥ (Well-Architected Framework)
1. **reliability** (ì‹ ë¢°ì„±): redundancy, failover, disaster recovery, SPOF, availability
2. **performance** (ì„±ëŠ¥): CDN, cache, latency, throughput, scalability, load balancing
3. **operational** (ìš´ì˜): monitoring, observability, logging, alerting, automation
4. **cost** (ë¹„ìš©): cost optimization, reserved instances, auto-scaling, resource utilization
5. **security** (ë³´ì•ˆ): encryption, authentication, authorization, IAM, key management
6. **sustainability** (ì§€ì†ê°€ëŠ¥ì„±): maintainability, extensibility, code quality, technical debt

### ê°•ì  vs ì•½ì  êµ¬ë¶„
- **strengths**: "good job", "excellent", "well done", "strong", "impressive"
- **gaps**: "missing", "forgot", "should have", "lacked", "didn't mention", "weak"

## Few-shot ì˜ˆì‹œ

### ì˜ˆì‹œ 1
**Input:** "Good job on handling NFRs and discussing CDN. However, candidate forgot to mention cost optimization strategies."
**Output:**
\`\`\`json
{
  "pillars": ["performance", "cost"],
  "strengths": [
    {
      "pillar": "performance",
      "point": "CDN ë…¼ì˜",
      "detail": "CDNì„ ì–¸ê¸‰í•˜ì—¬ ì„±ëŠ¥ ìµœì í™” ì´í•´ë„ë¥¼ ë³´ì„"
    }
  ],
  "gaps": [
    {
      "pillar": "cost",
      "point": "ë¹„ìš© ìµœì í™” ì „ëµ ëˆ„ë½",
      "detail": "ë¹„ìš© ìµœì í™” ì „ëµì„ ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ"
    }
  ],
  "keywords": ["NFRs", "CDN", "cost optimization"]
}
\`\`\`

### ì˜ˆì‹œ 2
**Input:** "Candidate struggled with redundancy. Mentioned SPOF but no concrete failover strategy. Also missing monitoring discussion."
**Output:**
\`\`\`json
{
  "pillars": ["reliability", "operational"],
  "strengths": [],
  "gaps": [
    {
      "pillar": "reliability",
      "point": "êµ¬ì²´ì ì¸ failover ì „ëµ ë¶€ì¡±",
      "detail": "SPOFë¥¼ ì–¸ê¸‰í–ˆìœ¼ë‚˜ êµ¬ì²´ì ì¸ failover ì „ëµ ì—†ìŒ"
    },
    {
      "pillar": "operational",
      "point": "ëª¨ë‹ˆí„°ë§ ë…¼ì˜ ëˆ„ë½",
      "detail": "ëª¨ë‹ˆí„°ë§ì— ëŒ€í•œ ì–¸ê¸‰ ì—†ìŒ"
    }
  ],
  "keywords": ["redundancy", "SPOF", "failover", "monitoring"]
}
\`\`\`

### ì˜ˆì‹œ 3
**Input:** "Excellent work on database choice justification. Candidate explained trade-offs between SQL and NoSQL clearly."
**Output:**
\`\`\`json
{
  "pillars": ["performance", "sustainability"],
  "strengths": [
    {
      "pillar": "performance",
      "point": "ë°ì´í„°ë² ì´ìŠ¤ ì„ íƒ ê·¼ê±° ëª…í™•",
      "detail": "SQL vs NoSQL íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ëª…í™•íˆ ì„¤ëª…"
    },
    {
      "pillar": "sustainability",
      "point": "íŠ¸ë ˆì´ë“œì˜¤í”„ ë…¼ì˜",
      "detail": "ì„¤ê³„ ê²°ì •ì— ëŒ€í•œ íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„"
    }
  ],
  "gaps": [],
  "keywords": ["database", "SQL", "NoSQL", "trade-offs"]
}
\`\`\`

## ì£¼ì˜ì‚¬í•­
1. **ë§¥ë½ ì´í•´:** ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ ë¬¸ë§¥ íŒŒì•…
2. **ê°•ì /ì•½ì  êµ¬ë¶„:** ê¸ì •ì  vs ë¶€ì •ì  ì˜ë¯¸ ì •í™•íˆ íŒë‹¨
3. **ë‹¤ì¤‘ ê¸°ë‘¥:** í•˜ë‚˜ì˜ í¬ì¸íŠ¸ê°€ ì—¬ëŸ¬ ê¸°ë‘¥ì— ê±¸ì¹  ìˆ˜ ìˆìŒ
4. **êµ¬ì²´ì„±:** detailì—ëŠ” êµ¬ì²´ì ì¸ ì´ìœ /ìƒí™© í¬í•¨

## ì¶œë ¥ í˜•ì‹ (JSONë§Œ)
\`\`\`json
{
  "pillars": ["pillar1", "pillar2"],
  "strengths": [
    { "pillar": "...", "point": "...", "detail": "..." }
  ],
  "gaps": [
    { "pillar": "...", "point": "...", "detail": "..." }
  ],
  "keywords": ["keyword1", "keyword2"]
}
\`\`\`
`;

  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${getApiKey()}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [{ role: 'user', content: prompt }],
        max_tokens: 800,
        temperature: 0.3  // ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ë¶„ë¥˜
      })
    });

    if (!response.ok) {
      throw new Error(`LLM API Error: ${response.status}`);
    }

    const data = await response.json();
    const content = data.choices[0].message.content.trim();

    // JSON ì¶”ì¶œ
    const jsonMatch = content.match(/```json\s*([\s\S]*?)\s*```/) || content.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const jsonStr = jsonMatch[1] || jsonMatch[0];
      return JSON.parse(jsonStr);
    }

    throw new Error('LLMì´ JSON í˜•ì‹ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ');
  } catch (error) {
    console.error('[LLM ë¶„ë¥˜ ì‹¤íŒ¨]', error);

    // Fallback: ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ (ìµœì†Œí•œì˜ ë¶„ë¥˜)
    return fallbackKeywordClassification(summary, title);
  }
}

/**
 * Fallback: ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë¶„ë¥˜
 *
 * LLM ì‹¤íŒ¨ ì‹œ ìµœì†Œí•œì˜ ë¶„ë¥˜ ì œê³µ
 */
function fallbackKeywordClassification(summary, title) {
  const lowerSummary = summary.toLowerCase();
  const lowerTitle = title.toLowerCase();
  const text = `${lowerSummary} ${lowerTitle}`;

  const pillarKeywords = {
    reliability: ['redundancy', 'failover', 'availability', 'spof', 'disaster', 'recovery'],
    performance: ['cdn', 'cache', 'latency', 'throughput', 'scalability', 'performance'],
    operational: ['monitoring', 'observability', 'logging', 'alerting', 'telemetry'],
    cost: ['cost', 'pricing', 'budget', 'reserved', 'spot instance'],
    security: ['encryption', 'authentication', 'authorization', 'security', 'access control'],
    sustainability: ['maintainability', 'extensibility', 'technical debt', 'refactor']
  };

  const detectedPillars = [];
  const keywords = [];

  Object.entries(pillarKeywords).forEach(([pillar, kws]) => {
    const found = kws.some(kw => text.includes(kw));
    if (found) {
      detectedPillars.push(pillar);
      keywords.push(...kws.filter(kw => text.includes(kw)));
    }
  });

  // ê°•ì /ì•½ì  ê°„ë‹¨ êµ¬ë¶„
  const hasPositive = /(good|excellent|strong|well|impressive)/i.test(summary);
  const hasNegative = /(missing|forgot|lack|weak|should|didn't)/i.test(summary);

  const gaps = hasNegative ? [
    {
      pillar: detectedPillars[0] || 'unknown',
      point: 'êµ¬ì²´ì  ë‚´ìš© í™•ì¸ í•„ìš”',
      detail: summary.substring(0, 100)
    }
  ] : [];

  return {
    pillars: detectedPillars,
    strengths: [],  // Fallbackì—ì„œëŠ” ìƒì„¸ ë¶„ë¥˜ ìƒëµ
    gaps,
    keywords: [...new Set(keywords)],
    _fallback: true  // Fallback ì‚¬ìš© í‘œì‹œ
  };
}

/**
 * ë°°ì¹˜ ë¶„ë¥˜: ì—¬ëŸ¬ ë©´ì ‘ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ë¶„ë¥˜
 *
 * @param {Array} interviews - [{ title, summary, ... }, ...]
 * @param {Object} options - { batchSize: 5, delayMs: 1000 }
 * @returns {Promise<Array>} ë¶„ë¥˜ ê²°ê³¼ ë°°ì—´
 */
export async function batchClassifyInterviews(interviews, options = {}) {
  const { batchSize = 5, delayMs = 1000 } = options;

  console.log(`ğŸ¤– [LLM ë¶„ë¥˜] ${interviews.length}ê°œ ë©´ì ‘ ë°ì´í„° ë¶„ë¥˜ ì‹œì‘...`);

  const results = [];
  const batches = [];

  // ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸° (API ìš”ì²­ ì œí•œ ê³ ë ¤)
  for (let i = 0; i < interviews.length; i += batchSize) {
    batches.push(interviews.slice(i, i + batchSize));
  }

  for (let i = 0; i < batches.length; i++) {
    const batch = batches[i];
    console.log(`   ë°°ì¹˜ ${i + 1}/${batches.length} ì²˜ë¦¬ ì¤‘...`);

    const batchResults = await Promise.allSettled(
      batch.map(interview =>
        classifyInterviewFeedback(interview.summary, interview.title)
      )
    );

    batchResults.forEach((result, idx) => {
      const interview = batch[idx];

      if (result.status === 'fulfilled') {
        results.push({
          ...interview,
          classification: result.value
        });
      } else {
        console.warn(`   âš ï¸ ë¶„ë¥˜ ì‹¤íŒ¨: ${interview.title}`, result.reason);
        results.push({
          ...interview,
          classification: fallbackKeywordClassification(interview.summary, interview.title)
        });
      }
    });

    // ë‹¤ìŒ ë°°ì¹˜ ì „ ëŒ€ê¸° (Rate limit ë°©ì§€)
    if (i < batches.length - 1) {
      await new Promise(resolve => setTimeout(resolve, delayMs));
    }
  }

  const successCount = results.filter(r => !r.classification._fallback).length;
  const fallbackCount = results.filter(r => r.classification._fallback).length;

  console.log(`âœ… [ë¶„ë¥˜ ì™„ë£Œ] ì„±ê³µ: ${successCount}, Fallback: ${fallbackCount}`);

  return results;
}

/**
 * ì‚¬ìš© ì˜ˆì‹œ:
 *
 * import { classifyInterviewFeedback, batchClassifyInterviews } from './llmBasedClassifier';
 *
 * // ë‹¨ì¼ ë¶„ë¥˜
 * const result = await classifyInterviewFeedback(
 *   "Good job on CDN, but missing cost discussion",
 *   "Design YouTube"
 * );
 *
 * // ë°°ì¹˜ ë¶„ë¥˜
 * const interviews = loadAllInterviews();
 * const classified = await batchClassifyInterviews(interviews, {
 *   batchSize: 3,  // í•œ ë²ˆì— 3ê°œì”©
 *   delayMs: 2000  // 2ì´ˆ ëŒ€ê¸°
 * });
 */
